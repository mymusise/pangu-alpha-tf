{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "backbone.blocks.0.layernorm1.gamma\n",
      "backbone.blocks.0.layernorm1.beta\n",
      "backbone.blocks.0.layernorm2.gamma\n",
      "backbone.blocks.0.layernorm2.beta\n",
      "backbone.blocks.0.attention.projection.weight\n",
      "backbone.blocks.0.attention.projection.bias\n",
      "backbone.blocks.0.attention.dense1.weight\n",
      "backbone.blocks.0.attention.dense1.bias\n",
      "backbone.blocks.0.attention.dense2.weight\n",
      "backbone.blocks.0.attention.dense2.bias\n",
      "backbone.blocks.0.attention.dense3.weight\n",
      "backbone.blocks.0.attention.dense3.bias\n",
      "backbone.blocks.0.output.mapping.weight\n",
      "backbone.blocks.0.output.mapping.bias\n",
      "backbone.blocks.0.output.projection.weight\n",
      "backbone.blocks.0.output.projection.bias\n",
      "backbone.blocks.1.layernorm1.gamma\n",
      "backbone.blocks.1.layernorm1.beta\n",
      "backbone.blocks.1.layernorm2.gamma\n",
      "backbone.blocks.1.layernorm2.beta\n",
      "backbone.blocks.1.attention.projection.weight\n",
      "backbone.blocks.1.attention.projection.bias\n",
      "backbone.blocks.1.attention.dense1.weight\n",
      "backbone.blocks.1.attention.dense1.bias\n",
      "backbone.blocks.1.attention.dense2.weight\n",
      "backbone.blocks.1.attention.dense2.bias\n",
      "backbone.blocks.1.attention.dense3.weight\n",
      "backbone.blocks.1.attention.dense3.bias\n",
      "backbone.blocks.1.output.mapping.weight\n",
      "backbone.blocks.1.output.mapping.bias\n",
      "backbone.blocks.1.output.projection.weight\n",
      "backbone.blocks.1.output.projection.bias\n",
      "backbone.blocks.2.layernorm1.gamma\n",
      "backbone.blocks.2.layernorm1.beta\n",
      "backbone.blocks.2.layernorm2.gamma\n",
      "backbone.blocks.2.layernorm2.beta\n",
      "backbone.blocks.2.attention.projection.weight\n",
      "backbone.blocks.2.attention.projection.bias\n",
      "backbone.blocks.2.attention.dense1.weight\n",
      "backbone.blocks.2.attention.dense1.bias\n",
      "backbone.blocks.2.attention.dense2.weight\n",
      "backbone.blocks.2.attention.dense2.bias\n",
      "backbone.blocks.2.attention.dense3.weight\n",
      "backbone.blocks.2.attention.dense3.bias\n",
      "backbone.blocks.2.output.mapping.weight\n",
      "backbone.blocks.2.output.mapping.bias\n",
      "backbone.blocks.2.output.projection.weight\n",
      "backbone.blocks.2.output.projection.bias\n",
      "backbone.blocks.3.layernorm1.gamma\n",
      "backbone.blocks.3.layernorm1.beta\n",
      "backbone.blocks.3.layernorm2.gamma\n",
      "backbone.blocks.3.layernorm2.beta\n",
      "backbone.blocks.3.attention.projection.weight\n",
      "backbone.blocks.3.attention.projection.bias\n",
      "backbone.blocks.3.attention.dense1.weight\n",
      "backbone.blocks.3.attention.dense1.bias\n",
      "backbone.blocks.3.attention.dense2.weight\n",
      "backbone.blocks.3.attention.dense2.bias\n",
      "backbone.blocks.3.attention.dense3.weight\n",
      "backbone.blocks.3.attention.dense3.bias\n",
      "backbone.blocks.3.output.mapping.weight\n",
      "backbone.blocks.3.output.mapping.bias\n",
      "backbone.blocks.3.output.projection.weight\n",
      "backbone.blocks.3.output.projection.bias\n",
      "backbone.blocks.4.layernorm1.gamma\n",
      "backbone.blocks.4.layernorm1.beta\n",
      "backbone.blocks.4.layernorm2.gamma\n",
      "backbone.blocks.4.layernorm2.beta\n",
      "backbone.blocks.4.attention.projection.weight\n",
      "backbone.blocks.4.attention.projection.bias\n",
      "backbone.blocks.4.attention.dense1.weight\n",
      "backbone.blocks.4.attention.dense1.bias\n",
      "backbone.blocks.4.attention.dense2.weight\n",
      "backbone.blocks.4.attention.dense2.bias\n",
      "backbone.blocks.4.attention.dense3.weight\n",
      "backbone.blocks.4.attention.dense3.bias\n",
      "backbone.blocks.4.output.mapping.weight\n",
      "backbone.blocks.4.output.mapping.bias\n",
      "backbone.blocks.4.output.projection.weight\n",
      "backbone.blocks.4.output.projection.bias\n",
      "backbone.blocks.5.layernorm1.gamma\n",
      "backbone.blocks.5.layernorm1.beta\n",
      "backbone.blocks.5.layernorm2.gamma\n",
      "backbone.blocks.5.layernorm2.beta\n",
      "backbone.blocks.5.attention.projection.weight\n",
      "backbone.blocks.5.attention.projection.bias\n",
      "backbone.blocks.5.attention.dense1.weight\n",
      "backbone.blocks.5.attention.dense1.bias\n",
      "backbone.blocks.5.attention.dense2.weight\n",
      "backbone.blocks.5.attention.dense2.bias\n",
      "backbone.blocks.5.attention.dense3.weight\n",
      "backbone.blocks.5.attention.dense3.bias\n",
      "backbone.blocks.5.output.mapping.weight\n",
      "backbone.blocks.5.output.mapping.bias\n",
      "backbone.blocks.5.output.projection.weight\n",
      "backbone.blocks.5.output.projection.bias\n",
      "backbone.blocks.6.layernorm1.gamma\n",
      "backbone.blocks.6.layernorm1.beta\n",
      "backbone.blocks.6.layernorm2.gamma\n",
      "backbone.blocks.6.layernorm2.beta\n",
      "backbone.blocks.6.attention.projection.weight\n",
      "backbone.blocks.6.attention.projection.bias\n",
      "backbone.blocks.6.attention.dense1.weight\n",
      "backbone.blocks.6.attention.dense1.bias\n",
      "backbone.blocks.6.attention.dense2.weight\n",
      "backbone.blocks.6.attention.dense2.bias\n",
      "backbone.blocks.6.attention.dense3.weight\n",
      "backbone.blocks.6.attention.dense3.bias\n",
      "backbone.blocks.6.output.mapping.weight\n",
      "backbone.blocks.6.output.mapping.bias\n",
      "backbone.blocks.6.output.projection.weight\n",
      "backbone.blocks.6.output.projection.bias\n",
      "backbone.blocks.7.layernorm1.gamma\n",
      "backbone.blocks.7.layernorm1.beta\n",
      "backbone.blocks.7.layernorm2.gamma\n",
      "backbone.blocks.7.layernorm2.beta\n",
      "backbone.blocks.7.attention.projection.weight\n",
      "backbone.blocks.7.attention.projection.bias\n",
      "backbone.blocks.7.attention.dense1.weight\n",
      "backbone.blocks.7.attention.dense1.bias\n",
      "backbone.blocks.7.attention.dense2.weight\n",
      "backbone.blocks.7.attention.dense2.bias\n",
      "backbone.blocks.7.attention.dense3.weight\n",
      "backbone.blocks.7.attention.dense3.bias\n",
      "backbone.blocks.7.output.mapping.weight\n",
      "backbone.blocks.7.output.mapping.bias\n",
      "backbone.blocks.7.output.projection.weight\n",
      "backbone.blocks.7.output.projection.bias\n",
      "backbone.blocks.8.layernorm1.gamma\n",
      "backbone.blocks.8.layernorm1.beta\n",
      "backbone.blocks.8.layernorm2.gamma\n",
      "backbone.blocks.8.layernorm2.beta\n",
      "backbone.blocks.8.attention.projection.weight\n",
      "backbone.blocks.8.attention.projection.bias\n",
      "backbone.blocks.8.attention.dense1.weight\n",
      "backbone.blocks.8.attention.dense1.bias\n",
      "backbone.blocks.8.attention.dense2.weight\n",
      "backbone.blocks.8.attention.dense2.bias\n",
      "backbone.blocks.8.attention.dense3.weight\n",
      "backbone.blocks.8.attention.dense3.bias\n",
      "backbone.blocks.8.output.mapping.weight\n",
      "backbone.blocks.8.output.mapping.bias\n",
      "backbone.blocks.8.output.projection.weight\n",
      "backbone.blocks.8.output.projection.bias\n",
      "backbone.blocks.9.layernorm1.gamma\n",
      "backbone.blocks.9.layernorm1.beta\n",
      "backbone.blocks.9.layernorm2.gamma\n",
      "backbone.blocks.9.layernorm2.beta\n",
      "backbone.blocks.9.attention.projection.weight\n",
      "backbone.blocks.9.attention.projection.bias\n",
      "backbone.blocks.9.attention.dense1.weight\n",
      "backbone.blocks.9.attention.dense1.bias\n",
      "backbone.blocks.9.attention.dense2.weight\n",
      "backbone.blocks.9.attention.dense2.bias\n",
      "backbone.blocks.9.attention.dense3.weight\n",
      "backbone.blocks.9.attention.dense3.bias\n",
      "backbone.blocks.9.output.mapping.weight\n",
      "backbone.blocks.9.output.mapping.bias\n",
      "backbone.blocks.9.output.projection.weight\n",
      "backbone.blocks.9.output.projection.bias\n",
      "backbone.blocks.10.layernorm1.gamma\n",
      "backbone.blocks.10.layernorm1.beta\n",
      "backbone.blocks.10.layernorm2.gamma\n",
      "backbone.blocks.10.layernorm2.beta\n",
      "backbone.blocks.10.attention.projection.weight\n",
      "backbone.blocks.10.attention.projection.bias\n",
      "backbone.blocks.10.attention.dense1.weight\n",
      "backbone.blocks.10.attention.dense1.bias\n",
      "backbone.blocks.10.attention.dense2.weight\n",
      "backbone.blocks.10.attention.dense2.bias\n",
      "backbone.blocks.10.attention.dense3.weight\n",
      "backbone.blocks.10.attention.dense3.bias\n",
      "backbone.blocks.10.output.mapping.weight\n",
      "backbone.blocks.10.output.mapping.bias\n",
      "backbone.blocks.10.output.projection.weight\n",
      "backbone.blocks.10.output.projection.bias\n",
      "backbone.blocks.11.layernorm1.gamma\n",
      "backbone.blocks.11.layernorm1.beta\n",
      "backbone.blocks.11.layernorm2.gamma\n",
      "backbone.blocks.11.layernorm2.beta\n",
      "backbone.blocks.11.attention.projection.weight\n",
      "backbone.blocks.11.attention.projection.bias\n",
      "backbone.blocks.11.attention.dense1.weight\n",
      "backbone.blocks.11.attention.dense1.bias\n",
      "backbone.blocks.11.attention.dense2.weight\n",
      "backbone.blocks.11.attention.dense2.bias\n",
      "backbone.blocks.11.attention.dense3.weight\n",
      "backbone.blocks.11.attention.dense3.bias\n",
      "backbone.blocks.11.output.mapping.weight\n",
      "backbone.blocks.11.output.mapping.bias\n",
      "backbone.blocks.11.output.projection.weight\n",
      "backbone.blocks.11.output.projection.bias\n",
      "backbone.blocks.12.layernorm1.gamma\n",
      "backbone.blocks.12.layernorm1.beta\n",
      "backbone.blocks.12.layernorm2.gamma\n",
      "backbone.blocks.12.layernorm2.beta\n",
      "backbone.blocks.12.attention.projection.weight\n",
      "backbone.blocks.12.attention.projection.bias\n",
      "backbone.blocks.12.attention.dense1.weight\n",
      "backbone.blocks.12.attention.dense1.bias\n",
      "backbone.blocks.12.attention.dense2.weight\n",
      "backbone.blocks.12.attention.dense2.bias\n",
      "backbone.blocks.12.attention.dense3.weight\n",
      "backbone.blocks.12.attention.dense3.bias\n",
      "backbone.blocks.12.output.mapping.weight\n",
      "backbone.blocks.12.output.mapping.bias\n",
      "backbone.blocks.12.output.projection.weight\n",
      "backbone.blocks.12.output.projection.bias\n",
      "backbone.blocks.13.layernorm1.gamma\n",
      "backbone.blocks.13.layernorm1.beta\n",
      "backbone.blocks.13.layernorm2.gamma\n",
      "backbone.blocks.13.layernorm2.beta\n",
      "backbone.blocks.13.attention.projection.weight\n",
      "backbone.blocks.13.attention.projection.bias\n",
      "backbone.blocks.13.attention.dense1.weight\n",
      "backbone.blocks.13.attention.dense1.bias\n",
      "backbone.blocks.13.attention.dense2.weight\n",
      "backbone.blocks.13.attention.dense2.bias\n",
      "backbone.blocks.13.attention.dense3.weight\n",
      "backbone.blocks.13.attention.dense3.bias\n",
      "backbone.blocks.13.output.mapping.weight\n",
      "backbone.blocks.13.output.mapping.bias\n",
      "backbone.blocks.13.output.projection.weight\n",
      "backbone.blocks.13.output.projection.bias\n",
      "backbone.blocks.14.layernorm1.gamma\n",
      "backbone.blocks.14.layernorm1.beta\n",
      "backbone.blocks.14.layernorm2.gamma\n",
      "backbone.blocks.14.layernorm2.beta\n",
      "backbone.blocks.14.attention.projection.weight\n",
      "backbone.blocks.14.attention.projection.bias\n",
      "backbone.blocks.14.attention.dense1.weight\n",
      "backbone.blocks.14.attention.dense1.bias\n",
      "backbone.blocks.14.attention.dense2.weight\n",
      "backbone.blocks.14.attention.dense2.bias\n",
      "backbone.blocks.14.attention.dense3.weight\n",
      "backbone.blocks.14.attention.dense3.bias\n",
      "backbone.blocks.14.output.mapping.weight\n",
      "backbone.blocks.14.output.mapping.bias\n",
      "backbone.blocks.14.output.projection.weight\n",
      "backbone.blocks.14.output.projection.bias\n",
      "backbone.blocks.15.layernorm1.gamma\n",
      "backbone.blocks.15.layernorm1.beta\n",
      "backbone.blocks.15.layernorm2.gamma\n",
      "backbone.blocks.15.layernorm2.beta\n",
      "backbone.blocks.15.attention.projection.weight\n",
      "backbone.blocks.15.attention.projection.bias\n",
      "backbone.blocks.15.attention.dense1.weight\n",
      "backbone.blocks.15.attention.dense1.bias\n",
      "backbone.blocks.15.attention.dense2.weight\n",
      "backbone.blocks.15.attention.dense2.bias\n",
      "backbone.blocks.15.attention.dense3.weight\n",
      "backbone.blocks.15.attention.dense3.bias\n",
      "backbone.blocks.15.output.mapping.weight\n",
      "backbone.blocks.15.output.mapping.bias\n",
      "backbone.blocks.15.output.projection.weight\n",
      "backbone.blocks.15.output.projection.bias\n",
      "backbone.blocks.16.layernorm1.gamma\n",
      "backbone.blocks.16.layernorm1.beta\n",
      "backbone.blocks.16.layernorm2.gamma\n",
      "backbone.blocks.16.layernorm2.beta\n",
      "backbone.blocks.16.attention.projection.weight\n",
      "backbone.blocks.16.attention.projection.bias\n",
      "backbone.blocks.16.attention.dense1.weight\n",
      "backbone.blocks.16.attention.dense1.bias\n",
      "backbone.blocks.16.attention.dense2.weight\n",
      "backbone.blocks.16.attention.dense2.bias\n",
      "backbone.blocks.16.attention.dense3.weight\n",
      "backbone.blocks.16.attention.dense3.bias\n",
      "backbone.blocks.16.output.mapping.weight\n",
      "backbone.blocks.16.output.mapping.bias\n",
      "backbone.blocks.16.output.projection.weight\n",
      "backbone.blocks.16.output.projection.bias\n",
      "backbone.blocks.17.layernorm1.gamma\n",
      "backbone.blocks.17.layernorm1.beta\n",
      "backbone.blocks.17.layernorm2.gamma\n",
      "backbone.blocks.17.layernorm2.beta\n",
      "backbone.blocks.17.attention.projection.weight\n",
      "backbone.blocks.17.attention.projection.bias\n",
      "backbone.blocks.17.attention.dense1.weight\n",
      "backbone.blocks.17.attention.dense1.bias\n",
      "backbone.blocks.17.attention.dense2.weight\n",
      "backbone.blocks.17.attention.dense2.bias\n",
      "backbone.blocks.17.attention.dense3.weight\n",
      "backbone.blocks.17.attention.dense3.bias\n",
      "backbone.blocks.17.output.mapping.weight\n",
      "backbone.blocks.17.output.mapping.bias\n",
      "backbone.blocks.17.output.projection.weight\n",
      "backbone.blocks.17.output.projection.bias\n",
      "backbone.blocks.18.layernorm1.gamma\n",
      "backbone.blocks.18.layernorm1.beta\n",
      "backbone.blocks.18.layernorm2.gamma\n",
      "backbone.blocks.18.layernorm2.beta\n",
      "backbone.blocks.18.attention.projection.weight\n",
      "backbone.blocks.18.attention.projection.bias\n",
      "backbone.blocks.18.attention.dense1.weight\n",
      "backbone.blocks.18.attention.dense1.bias\n",
      "backbone.blocks.18.attention.dense2.weight\n",
      "backbone.blocks.18.attention.dense2.bias\n",
      "backbone.blocks.18.attention.dense3.weight\n",
      "backbone.blocks.18.attention.dense3.bias\n",
      "backbone.blocks.18.output.mapping.weight\n",
      "backbone.blocks.18.output.mapping.bias\n",
      "backbone.blocks.18.output.projection.weight\n",
      "backbone.blocks.18.output.projection.bias\n",
      "backbone.blocks.19.layernorm1.gamma\n",
      "backbone.blocks.19.layernorm1.beta\n",
      "backbone.blocks.19.layernorm2.gamma\n",
      "backbone.blocks.19.layernorm2.beta\n",
      "backbone.blocks.19.attention.projection.weight\n",
      "backbone.blocks.19.attention.projection.bias\n",
      "backbone.blocks.19.attention.dense1.weight\n",
      "backbone.blocks.19.attention.dense1.bias\n",
      "backbone.blocks.19.attention.dense2.weight\n",
      "backbone.blocks.19.attention.dense2.bias\n",
      "backbone.blocks.19.attention.dense3.weight\n",
      "backbone.blocks.19.attention.dense3.bias\n",
      "backbone.blocks.19.output.mapping.weight\n",
      "backbone.blocks.19.output.mapping.bias\n",
      "backbone.blocks.19.output.projection.weight\n",
      "backbone.blocks.19.output.projection.bias\n",
      "backbone.blocks.20.layernorm1.gamma\n",
      "backbone.blocks.20.layernorm1.beta\n",
      "backbone.blocks.20.layernorm2.gamma\n",
      "backbone.blocks.20.layernorm2.beta\n",
      "backbone.blocks.20.attention.projection.weight\n",
      "backbone.blocks.20.attention.projection.bias\n",
      "backbone.blocks.20.attention.dense1.weight\n",
      "backbone.blocks.20.attention.dense1.bias\n",
      "backbone.blocks.20.attention.dense2.weight\n",
      "backbone.blocks.20.attention.dense2.bias\n",
      "backbone.blocks.20.attention.dense3.weight\n",
      "backbone.blocks.20.attention.dense3.bias\n",
      "backbone.blocks.20.output.mapping.weight\n",
      "backbone.blocks.20.output.mapping.bias\n",
      "backbone.blocks.20.output.projection.weight\n",
      "backbone.blocks.20.output.projection.bias\n",
      "backbone.blocks.21.layernorm1.gamma\n",
      "backbone.blocks.21.layernorm1.beta\n",
      "backbone.blocks.21.layernorm2.gamma\n",
      "backbone.blocks.21.layernorm2.beta\n",
      "backbone.blocks.21.attention.projection.weight\n",
      "backbone.blocks.21.attention.projection.bias\n",
      "backbone.blocks.21.attention.dense1.weight\n",
      "backbone.blocks.21.attention.dense1.bias\n",
      "backbone.blocks.21.attention.dense2.weight\n",
      "backbone.blocks.21.attention.dense2.bias\n",
      "backbone.blocks.21.attention.dense3.weight\n",
      "backbone.blocks.21.attention.dense3.bias\n",
      "backbone.blocks.21.output.mapping.weight\n",
      "backbone.blocks.21.output.mapping.bias\n",
      "backbone.blocks.21.output.projection.weight\n",
      "backbone.blocks.21.output.projection.bias\n",
      "backbone.blocks.22.layernorm1.gamma\n",
      "backbone.blocks.22.layernorm1.beta\n",
      "backbone.blocks.22.layernorm2.gamma\n",
      "backbone.blocks.22.layernorm2.beta\n",
      "backbone.blocks.22.attention.projection.weight\n",
      "backbone.blocks.22.attention.projection.bias\n",
      "backbone.blocks.22.attention.dense1.weight\n",
      "backbone.blocks.22.attention.dense1.bias\n",
      "backbone.blocks.22.attention.dense2.weight\n",
      "backbone.blocks.22.attention.dense2.bias\n",
      "backbone.blocks.22.attention.dense3.weight\n",
      "backbone.blocks.22.attention.dense3.bias\n",
      "backbone.blocks.22.output.mapping.weight\n",
      "backbone.blocks.22.output.mapping.bias\n",
      "backbone.blocks.22.output.projection.weight\n",
      "backbone.blocks.22.output.projection.bias\n",
      "backbone.blocks.23.layernorm1.gamma\n",
      "backbone.blocks.23.layernorm1.beta\n",
      "backbone.blocks.23.layernorm2.gamma\n",
      "backbone.blocks.23.layernorm2.beta\n",
      "backbone.blocks.23.attention.projection.weight\n",
      "backbone.blocks.23.attention.projection.bias\n",
      "backbone.blocks.23.attention.dense1.weight\n",
      "backbone.blocks.23.attention.dense1.bias\n",
      "backbone.blocks.23.attention.dense2.weight\n",
      "backbone.blocks.23.attention.dense2.bias\n",
      "backbone.blocks.23.attention.dense3.weight\n",
      "backbone.blocks.23.attention.dense3.bias\n",
      "backbone.blocks.23.output.mapping.weight\n",
      "backbone.blocks.23.output.mapping.bias\n",
      "backbone.blocks.23.output.projection.weight\n",
      "backbone.blocks.23.output.projection.bias\n",
      "backbone.blocks.24.layernorm1.gamma\n",
      "backbone.blocks.24.layernorm1.beta\n",
      "backbone.blocks.24.layernorm2.gamma\n",
      "backbone.blocks.24.layernorm2.beta\n",
      "backbone.blocks.24.attention.projection.weight\n",
      "backbone.blocks.24.attention.projection.bias\n",
      "backbone.blocks.24.attention.dense1.weight\n",
      "backbone.blocks.24.attention.dense1.bias\n",
      "backbone.blocks.24.attention.dense2.weight\n",
      "backbone.blocks.24.attention.dense2.bias\n",
      "backbone.blocks.24.attention.dense3.weight\n",
      "backbone.blocks.24.attention.dense3.bias\n",
      "backbone.blocks.24.output.mapping.weight\n",
      "backbone.blocks.24.output.mapping.bias\n",
      "backbone.blocks.24.output.projection.weight\n",
      "backbone.blocks.24.output.projection.bias\n",
      "backbone.blocks.25.layernorm1.gamma\n",
      "backbone.blocks.25.layernorm1.beta\n",
      "backbone.blocks.25.layernorm2.gamma\n",
      "backbone.blocks.25.layernorm2.beta\n",
      "backbone.blocks.25.attention.projection.weight\n",
      "backbone.blocks.25.attention.projection.bias\n",
      "backbone.blocks.25.attention.dense1.weight\n",
      "backbone.blocks.25.attention.dense1.bias\n",
      "backbone.blocks.25.attention.dense2.weight\n",
      "backbone.blocks.25.attention.dense2.bias\n",
      "backbone.blocks.25.attention.dense3.weight\n",
      "backbone.blocks.25.attention.dense3.bias\n",
      "backbone.blocks.25.output.mapping.weight\n",
      "backbone.blocks.25.output.mapping.bias\n",
      "backbone.blocks.25.output.projection.weight\n",
      "backbone.blocks.25.output.projection.bias\n",
      "backbone.blocks.26.layernorm1.gamma\n",
      "backbone.blocks.26.layernorm1.beta\n",
      "backbone.blocks.26.layernorm2.gamma\n",
      "backbone.blocks.26.layernorm2.beta\n",
      "backbone.blocks.26.attention.projection.weight\n",
      "backbone.blocks.26.attention.projection.bias\n",
      "backbone.blocks.26.attention.dense1.weight\n",
      "backbone.blocks.26.attention.dense1.bias\n",
      "backbone.blocks.26.attention.dense2.weight\n",
      "backbone.blocks.26.attention.dense2.bias\n",
      "backbone.blocks.26.attention.dense3.weight\n",
      "backbone.blocks.26.attention.dense3.bias\n",
      "backbone.blocks.26.output.mapping.weight\n",
      "backbone.blocks.26.output.mapping.bias\n",
      "backbone.blocks.26.output.projection.weight\n",
      "backbone.blocks.26.output.projection.bias\n",
      "backbone.blocks.27.layernorm1.gamma\n",
      "backbone.blocks.27.layernorm1.beta\n",
      "backbone.blocks.27.layernorm2.gamma\n",
      "backbone.blocks.27.layernorm2.beta\n",
      "backbone.blocks.27.attention.projection.weight\n",
      "backbone.blocks.27.attention.projection.bias\n",
      "backbone.blocks.27.attention.dense1.weight\n",
      "backbone.blocks.27.attention.dense1.bias\n",
      "backbone.blocks.27.attention.dense2.weight\n",
      "backbone.blocks.27.attention.dense2.bias\n",
      "backbone.blocks.27.attention.dense3.weight\n",
      "backbone.blocks.27.attention.dense3.bias\n",
      "backbone.blocks.27.output.mapping.weight\n",
      "backbone.blocks.27.output.mapping.bias\n",
      "backbone.blocks.27.output.projection.weight\n",
      "backbone.blocks.27.output.projection.bias\n",
      "backbone.blocks.28.layernorm1.gamma\n",
      "backbone.blocks.28.layernorm1.beta\n",
      "backbone.blocks.28.layernorm2.gamma\n",
      "backbone.blocks.28.layernorm2.beta\n",
      "backbone.blocks.28.attention.projection.weight\n",
      "backbone.blocks.28.attention.projection.bias\n",
      "backbone.blocks.28.attention.dense1.weight\n",
      "backbone.blocks.28.attention.dense1.bias\n",
      "backbone.blocks.28.attention.dense2.weight\n",
      "backbone.blocks.28.attention.dense2.bias\n",
      "backbone.blocks.28.attention.dense3.weight\n",
      "backbone.blocks.28.attention.dense3.bias\n",
      "backbone.blocks.28.output.mapping.weight\n",
      "backbone.blocks.28.output.mapping.bias\n",
      "backbone.blocks.28.output.projection.weight\n",
      "backbone.blocks.28.output.projection.bias\n",
      "backbone.blocks.29.layernorm1.gamma\n",
      "backbone.blocks.29.layernorm1.beta\n",
      "backbone.blocks.29.layernorm2.gamma\n",
      "backbone.blocks.29.layernorm2.beta\n",
      "backbone.blocks.29.attention.projection.weight\n",
      "backbone.blocks.29.attention.projection.bias\n",
      "backbone.blocks.29.attention.dense1.weight\n",
      "backbone.blocks.29.attention.dense1.bias\n",
      "backbone.blocks.29.attention.dense2.weight\n",
      "backbone.blocks.29.attention.dense2.bias\n",
      "backbone.blocks.29.attention.dense3.weight\n",
      "backbone.blocks.29.attention.dense3.bias\n",
      "backbone.blocks.29.output.mapping.weight\n",
      "backbone.blocks.29.output.mapping.bias\n",
      "backbone.blocks.29.output.projection.weight\n",
      "backbone.blocks.29.output.projection.bias\n",
      "backbone.blocks.30.layernorm1.gamma\n",
      "backbone.blocks.30.layernorm1.beta\n",
      "backbone.blocks.30.layernorm2.gamma\n",
      "backbone.blocks.30.layernorm2.beta\n",
      "backbone.blocks.30.attention.projection.weight\n",
      "backbone.blocks.30.attention.projection.bias\n",
      "backbone.blocks.30.attention.dense1.weight\n",
      "backbone.blocks.30.attention.dense1.bias\n",
      "backbone.blocks.30.attention.dense2.weight\n",
      "backbone.blocks.30.attention.dense2.bias\n",
      "backbone.blocks.30.attention.dense3.weight\n",
      "backbone.blocks.30.attention.dense3.bias\n",
      "backbone.blocks.30.output.mapping.weight\n",
      "backbone.blocks.30.output.mapping.bias\n",
      "backbone.blocks.30.output.projection.weight\n",
      "backbone.blocks.30.output.projection.bias\n",
      "backbone.layernorm.gamma\n",
      "backbone.layernorm.beta\n",
      "backbone.top_query_layer.layernorm1.gamma\n",
      "backbone.top_query_layer.layernorm1.beta\n",
      "backbone.top_query_layer.layernorm2.gamma\n",
      "backbone.top_query_layer.layernorm2.beta\n",
      "backbone.top_query_layer.attention.projection.weight\n",
      "backbone.top_query_layer.attention.projection.bias\n",
      "backbone.top_query_layer.attention.dense1.weight\n",
      "backbone.top_query_layer.attention.dense1.bias\n",
      "backbone.top_query_layer.attention.dense2.weight\n",
      "backbone.top_query_layer.attention.dense2.bias\n",
      "backbone.top_query_layer.attention.dense3.weight\n",
      "backbone.top_query_layer.attention.dense3.bias\n",
      "backbone.top_query_layer.output.mapping.weight\n",
      "backbone.top_query_layer.output.mapping.bias\n",
      "backbone.top_query_layer.output.projection.weight\n",
      "backbone.top_query_layer.output.projection.bias\n",
      "loss_scale\n",
      "global_step\n",
      "current_iterator_step\n",
      "last_overflow_iterator_step\n",
      "has_trained_step\n",
      "cur_epoch_num\n",
      "has_trained_epoch\n",
      "data_start_index\n",
      "cur_step_num\n",
      "loss_scale_value\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "out_path = \"/home/mymusise/Downloads/pangu_model/numpy_weights\"\n",
    "\n",
    "path = Path(out_path)\n",
    "\n",
    "files = path.glob('*.pickle')\n",
    "files = sorted(list(files), key=lambda x:x.stat().st_mtime)\n",
    "\n",
    "weights = {}\n",
    "\n",
    "for f in files:\n",
    "    f = str(f)\n",
    "    key = f.split('/')[-1]\n",
    "    keys = key.split('.')[:-1]\n",
    "    key = \".\".join(keys)\n",
    "    print(key)\n",
    "    with open(f, 'rb') as f:\n",
    "        w_list = pickle.load(f)\n",
    "        if type(w_list[0]) == np.ndarray and w_list[0].shape:                \n",
    "            w_list = np.concatenate(w_list, axis=0)\n",
    "        weights[key] = w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(name):\n",
    "    for key in weights.keys():\n",
    "        if name in key:\n",
    "            return weights[key]\n",
    "\n",
    "# print(get_weight(f'{block_name}.layernorm1.gamma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "backbone.blocks.0.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.0.layernorm1.beta (1310720,)\n",
      "backbone.blocks.0.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.0.layernorm2.beta (1310720,)\n",
      "backbone.blocks.0.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.projection.bias (1310720,)\n",
      "backbone.blocks.0.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.dense1.bias (2560,)\n",
      "backbone.blocks.0.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.dense2.bias (2560,)\n",
      "backbone.blocks.0.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.dense3.bias (2560,)\n",
      "backbone.blocks.0.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.0.output.mapping.bias (10240,)\n",
      "backbone.blocks.0.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.0.output.projection.bias (1310720,)\n",
      "backbone.blocks.1.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.1.layernorm1.beta (1310720,)\n",
      "backbone.blocks.1.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.1.layernorm2.beta (1310720,)\n",
      "backbone.blocks.1.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.projection.bias (1310720,)\n",
      "backbone.blocks.1.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.dense1.bias (2560,)\n",
      "backbone.blocks.1.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.dense2.bias (2560,)\n",
      "backbone.blocks.1.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.dense3.bias (2560,)\n",
      "backbone.blocks.1.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.1.output.mapping.bias (10240,)\n",
      "backbone.blocks.1.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.1.output.projection.bias (1310720,)\n",
      "backbone.blocks.2.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.2.layernorm1.beta (1310720,)\n",
      "backbone.blocks.2.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.2.layernorm2.beta (1310720,)\n",
      "backbone.blocks.2.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.projection.bias (1310720,)\n",
      "backbone.blocks.2.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.dense1.bias (2560,)\n",
      "backbone.blocks.2.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.dense2.bias (2560,)\n",
      "backbone.blocks.2.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.dense3.bias (2560,)\n",
      "backbone.blocks.2.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.2.output.mapping.bias (10240,)\n",
      "backbone.blocks.2.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.2.output.projection.bias (1310720,)\n",
      "backbone.blocks.3.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.3.layernorm1.beta (1310720,)\n",
      "backbone.blocks.3.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.3.layernorm2.beta (1310720,)\n",
      "backbone.blocks.3.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.projection.bias (1310720,)\n",
      "backbone.blocks.3.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.dense1.bias (2560,)\n",
      "backbone.blocks.3.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.dense2.bias (2560,)\n",
      "backbone.blocks.3.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.dense3.bias (2560,)\n",
      "backbone.blocks.3.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.3.output.mapping.bias (10240,)\n",
      "backbone.blocks.3.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.3.output.projection.bias (1310720,)\n",
      "backbone.blocks.4.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.4.layernorm1.beta (1310720,)\n",
      "backbone.blocks.4.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.4.layernorm2.beta (1310720,)\n",
      "backbone.blocks.4.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.projection.bias (1310720,)\n",
      "backbone.blocks.4.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.dense1.bias (2560,)\n",
      "backbone.blocks.4.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.dense2.bias (2560,)\n",
      "backbone.blocks.4.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.dense3.bias (2560,)\n",
      "backbone.blocks.4.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.4.output.mapping.bias (10240,)\n",
      "backbone.blocks.4.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.4.output.projection.bias (1310720,)\n",
      "backbone.blocks.5.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.5.layernorm1.beta (1310720,)\n",
      "backbone.blocks.5.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.5.layernorm2.beta (1310720,)\n",
      "backbone.blocks.5.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.projection.bias (1310720,)\n",
      "backbone.blocks.5.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.dense1.bias (2560,)\n",
      "backbone.blocks.5.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.dense2.bias (2560,)\n",
      "backbone.blocks.5.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.dense3.bias (2560,)\n",
      "backbone.blocks.5.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.5.output.mapping.bias (10240,)\n",
      "backbone.blocks.5.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.5.output.projection.bias (1310720,)\n",
      "backbone.blocks.6.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.6.layernorm1.beta (1310720,)\n",
      "backbone.blocks.6.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.6.layernorm2.beta (1310720,)\n",
      "backbone.blocks.6.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.projection.bias (1310720,)\n",
      "backbone.blocks.6.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.dense1.bias (2560,)\n",
      "backbone.blocks.6.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.dense2.bias (2560,)\n",
      "backbone.blocks.6.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.dense3.bias (2560,)\n",
      "backbone.blocks.6.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.6.output.mapping.bias (10240,)\n",
      "backbone.blocks.6.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.6.output.projection.bias (1310720,)\n",
      "backbone.blocks.7.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.7.layernorm1.beta (1310720,)\n",
      "backbone.blocks.7.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.7.layernorm2.beta (1310720,)\n",
      "backbone.blocks.7.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.projection.bias (1310720,)\n",
      "backbone.blocks.7.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.dense1.bias (2560,)\n",
      "backbone.blocks.7.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.dense2.bias (2560,)\n",
      "backbone.blocks.7.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.dense3.bias (2560,)\n",
      "backbone.blocks.7.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.7.output.mapping.bias (10240,)\n",
      "backbone.blocks.7.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.7.output.projection.bias (1310720,)\n",
      "backbone.blocks.8.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.8.layernorm1.beta (1310720,)\n",
      "backbone.blocks.8.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.8.layernorm2.beta (1310720,)\n",
      "backbone.blocks.8.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.projection.bias (1310720,)\n",
      "backbone.blocks.8.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.dense1.bias (2560,)\n",
      "backbone.blocks.8.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.dense2.bias (2560,)\n",
      "backbone.blocks.8.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.dense3.bias (2560,)\n",
      "backbone.blocks.8.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.8.output.mapping.bias (10240,)\n",
      "backbone.blocks.8.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.8.output.projection.bias (1310720,)\n",
      "backbone.blocks.9.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.9.layernorm1.beta (1310720,)\n",
      "backbone.blocks.9.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.9.layernorm2.beta (1310720,)\n",
      "backbone.blocks.9.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.projection.bias (1310720,)\n",
      "backbone.blocks.9.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.dense1.bias (2560,)\n",
      "backbone.blocks.9.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.dense2.bias (2560,)\n",
      "backbone.blocks.9.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.dense3.bias (2560,)\n",
      "backbone.blocks.9.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.9.output.mapping.bias (10240,)\n",
      "backbone.blocks.9.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.9.output.projection.bias (1310720,)\n",
      "backbone.blocks.10.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.10.layernorm1.beta (1310720,)\n",
      "backbone.blocks.10.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.10.layernorm2.beta (1310720,)\n",
      "backbone.blocks.10.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.projection.bias (1310720,)\n",
      "backbone.blocks.10.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.dense1.bias (2560,)\n",
      "backbone.blocks.10.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.dense2.bias (2560,)\n",
      "backbone.blocks.10.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.dense3.bias (2560,)\n",
      "backbone.blocks.10.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.10.output.mapping.bias (10240,)\n",
      "backbone.blocks.10.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.10.output.projection.bias (1310720,)\n",
      "backbone.blocks.11.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.11.layernorm1.beta (1310720,)\n",
      "backbone.blocks.11.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.11.layernorm2.beta (1310720,)\n",
      "backbone.blocks.11.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.projection.bias (1310720,)\n",
      "backbone.blocks.11.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.dense1.bias (2560,)\n",
      "backbone.blocks.11.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.dense2.bias (2560,)\n",
      "backbone.blocks.11.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.dense3.bias (2560,)\n",
      "backbone.blocks.11.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.11.output.mapping.bias (10240,)\n",
      "backbone.blocks.11.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.11.output.projection.bias (1310720,)\n",
      "backbone.blocks.12.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.12.layernorm1.beta (1310720,)\n",
      "backbone.blocks.12.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.12.layernorm2.beta (1310720,)\n",
      "backbone.blocks.12.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.projection.bias (1310720,)\n",
      "backbone.blocks.12.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.dense1.bias (2560,)\n",
      "backbone.blocks.12.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.dense2.bias (2560,)\n",
      "backbone.blocks.12.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.dense3.bias (2560,)\n",
      "backbone.blocks.12.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.12.output.mapping.bias (10240,)\n",
      "backbone.blocks.12.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.12.output.projection.bias (1310720,)\n",
      "backbone.blocks.13.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.13.layernorm1.beta (1310720,)\n",
      "backbone.blocks.13.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.13.layernorm2.beta (1310720,)\n",
      "backbone.blocks.13.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.projection.bias (1310720,)\n",
      "backbone.blocks.13.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.dense1.bias (2560,)\n",
      "backbone.blocks.13.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.dense2.bias (2560,)\n",
      "backbone.blocks.13.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.dense3.bias (2560,)\n",
      "backbone.blocks.13.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.13.output.mapping.bias (10240,)\n",
      "backbone.blocks.13.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.13.output.projection.bias (1310720,)\n",
      "backbone.blocks.14.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.14.layernorm1.beta (1310720,)\n",
      "backbone.blocks.14.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.14.layernorm2.beta (1310720,)\n",
      "backbone.blocks.14.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.projection.bias (1310720,)\n",
      "backbone.blocks.14.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.dense1.bias (2560,)\n",
      "backbone.blocks.14.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.dense2.bias (2560,)\n",
      "backbone.blocks.14.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.dense3.bias (2560,)\n",
      "backbone.blocks.14.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.14.output.mapping.bias (10240,)\n",
      "backbone.blocks.14.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.14.output.projection.bias (1310720,)\n",
      "backbone.blocks.15.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.15.layernorm1.beta (1310720,)\n",
      "backbone.blocks.15.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.15.layernorm2.beta (1310720,)\n",
      "backbone.blocks.15.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.projection.bias (1310720,)\n",
      "backbone.blocks.15.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.dense1.bias (2560,)\n",
      "backbone.blocks.15.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.dense2.bias (2560,)\n",
      "backbone.blocks.15.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.dense3.bias (2560,)\n",
      "backbone.blocks.15.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.15.output.mapping.bias (10240,)\n",
      "backbone.blocks.15.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.15.output.projection.bias (1310720,)\n",
      "backbone.blocks.16.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.16.layernorm1.beta (1310720,)\n",
      "backbone.blocks.16.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.16.layernorm2.beta (1310720,)\n",
      "backbone.blocks.16.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.projection.bias (1310720,)\n",
      "backbone.blocks.16.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.dense1.bias (2560,)\n",
      "backbone.blocks.16.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.dense2.bias (2560,)\n",
      "backbone.blocks.16.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.dense3.bias (2560,)\n",
      "backbone.blocks.16.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.16.output.mapping.bias (10240,)\n",
      "backbone.blocks.16.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.16.output.projection.bias (1310720,)\n",
      "backbone.blocks.17.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.17.layernorm1.beta (1310720,)\n",
      "backbone.blocks.17.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.17.layernorm2.beta (1310720,)\n",
      "backbone.blocks.17.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.projection.bias (1310720,)\n",
      "backbone.blocks.17.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.dense1.bias (2560,)\n",
      "backbone.blocks.17.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.dense2.bias (2560,)\n",
      "backbone.blocks.17.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.dense3.bias (2560,)\n",
      "backbone.blocks.17.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.17.output.mapping.bias (10240,)\n",
      "backbone.blocks.17.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.17.output.projection.bias (1310720,)\n",
      "backbone.blocks.18.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.18.layernorm1.beta (1310720,)\n",
      "backbone.blocks.18.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.18.layernorm2.beta (1310720,)\n",
      "backbone.blocks.18.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.projection.bias (1310720,)\n",
      "backbone.blocks.18.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.dense1.bias (2560,)\n",
      "backbone.blocks.18.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.dense2.bias (2560,)\n",
      "backbone.blocks.18.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.dense3.bias (2560,)\n",
      "backbone.blocks.18.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.18.output.mapping.bias (10240,)\n",
      "backbone.blocks.18.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.18.output.projection.bias (1310720,)\n",
      "backbone.blocks.19.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.19.layernorm1.beta (1310720,)\n",
      "backbone.blocks.19.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.19.layernorm2.beta (1310720,)\n",
      "backbone.blocks.19.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.projection.bias (1310720,)\n",
      "backbone.blocks.19.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.dense1.bias (2560,)\n",
      "backbone.blocks.19.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.dense2.bias (2560,)\n",
      "backbone.blocks.19.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.dense3.bias (2560,)\n",
      "backbone.blocks.19.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.19.output.mapping.bias (10240,)\n",
      "backbone.blocks.19.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.19.output.projection.bias (1310720,)\n",
      "backbone.blocks.20.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.20.layernorm1.beta (1310720,)\n",
      "backbone.blocks.20.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.20.layernorm2.beta (1310720,)\n",
      "backbone.blocks.20.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.projection.bias (1310720,)\n",
      "backbone.blocks.20.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.dense1.bias (2560,)\n",
      "backbone.blocks.20.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.dense2.bias (2560,)\n",
      "backbone.blocks.20.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.dense3.bias (2560,)\n",
      "backbone.blocks.20.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.20.output.mapping.bias (10240,)\n",
      "backbone.blocks.20.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.20.output.projection.bias (1310720,)\n",
      "backbone.blocks.21.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.21.layernorm1.beta (1310720,)\n",
      "backbone.blocks.21.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.21.layernorm2.beta (1310720,)\n",
      "backbone.blocks.21.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.projection.bias (1310720,)\n",
      "backbone.blocks.21.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.dense1.bias (2560,)\n",
      "backbone.blocks.21.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.dense2.bias (2560,)\n",
      "backbone.blocks.21.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.dense3.bias (2560,)\n",
      "backbone.blocks.21.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.21.output.mapping.bias (10240,)\n",
      "backbone.blocks.21.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.21.output.projection.bias (1310720,)\n",
      "backbone.blocks.22.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.22.layernorm1.beta (1310720,)\n",
      "backbone.blocks.22.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.22.layernorm2.beta (1310720,)\n",
      "backbone.blocks.22.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.projection.bias (1310720,)\n",
      "backbone.blocks.22.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.dense1.bias (2560,)\n",
      "backbone.blocks.22.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.dense2.bias (2560,)\n",
      "backbone.blocks.22.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.dense3.bias (2560,)\n",
      "backbone.blocks.22.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.22.output.mapping.bias (10240,)\n",
      "backbone.blocks.22.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.22.output.projection.bias (1310720,)\n",
      "backbone.blocks.23.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.23.layernorm1.beta (1310720,)\n",
      "backbone.blocks.23.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.23.layernorm2.beta (1310720,)\n",
      "backbone.blocks.23.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.projection.bias (1310720,)\n",
      "backbone.blocks.23.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.dense1.bias (2560,)\n",
      "backbone.blocks.23.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.dense2.bias (2560,)\n",
      "backbone.blocks.23.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.dense3.bias (2560,)\n",
      "backbone.blocks.23.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.23.output.mapping.bias (10240,)\n",
      "backbone.blocks.23.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.23.output.projection.bias (1310720,)\n",
      "backbone.blocks.24.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.24.layernorm1.beta (1310720,)\n",
      "backbone.blocks.24.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.24.layernorm2.beta (1310720,)\n",
      "backbone.blocks.24.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.projection.bias (1310720,)\n",
      "backbone.blocks.24.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.dense1.bias (2560,)\n",
      "backbone.blocks.24.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.dense2.bias (2560,)\n",
      "backbone.blocks.24.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.dense3.bias (2560,)\n",
      "backbone.blocks.24.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.24.output.mapping.bias (10240,)\n",
      "backbone.blocks.24.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.24.output.projection.bias (1310720,)\n",
      "backbone.blocks.25.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.25.layernorm1.beta (1310720,)\n",
      "backbone.blocks.25.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.25.layernorm2.beta (1310720,)\n",
      "backbone.blocks.25.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.projection.bias (1310720,)\n",
      "backbone.blocks.25.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.dense1.bias (2560,)\n",
      "backbone.blocks.25.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.dense2.bias (2560,)\n",
      "backbone.blocks.25.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.dense3.bias (2560,)\n",
      "backbone.blocks.25.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.25.output.mapping.bias (10240,)\n",
      "backbone.blocks.25.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.25.output.projection.bias (1310720,)\n",
      "backbone.blocks.26.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.26.layernorm1.beta (1310720,)\n",
      "backbone.blocks.26.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.26.layernorm2.beta (1310720,)\n",
      "backbone.blocks.26.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.projection.bias (1310720,)\n",
      "backbone.blocks.26.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.dense1.bias (2560,)\n",
      "backbone.blocks.26.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.dense2.bias (2560,)\n",
      "backbone.blocks.26.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.dense3.bias (2560,)\n",
      "backbone.blocks.26.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.26.output.mapping.bias (10240,)\n",
      "backbone.blocks.26.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.26.output.projection.bias (1310720,)\n",
      "backbone.blocks.27.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.27.layernorm1.beta (1310720,)\n",
      "backbone.blocks.27.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.27.layernorm2.beta (1310720,)\n",
      "backbone.blocks.27.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.projection.bias (1310720,)\n",
      "backbone.blocks.27.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.dense1.bias (2560,)\n",
      "backbone.blocks.27.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.dense2.bias (2560,)\n",
      "backbone.blocks.27.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.dense3.bias (2560,)\n",
      "backbone.blocks.27.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.27.output.mapping.bias (10240,)\n",
      "backbone.blocks.27.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.27.output.projection.bias (1310720,)\n",
      "backbone.blocks.28.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.28.layernorm1.beta (1310720,)\n",
      "backbone.blocks.28.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.28.layernorm2.beta (1310720,)\n",
      "backbone.blocks.28.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.projection.bias (1310720,)\n",
      "backbone.blocks.28.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.dense1.bias (2560,)\n",
      "backbone.blocks.28.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.dense2.bias (2560,)\n",
      "backbone.blocks.28.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.dense3.bias (2560,)\n",
      "backbone.blocks.28.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.28.output.mapping.bias (10240,)\n",
      "backbone.blocks.28.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.28.output.projection.bias (1310720,)\n",
      "backbone.blocks.29.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.29.layernorm1.beta (1310720,)\n",
      "backbone.blocks.29.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.29.layernorm2.beta (1310720,)\n",
      "backbone.blocks.29.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.projection.bias (1310720,)\n",
      "backbone.blocks.29.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.dense1.bias (2560,)\n",
      "backbone.blocks.29.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.dense2.bias (2560,)\n",
      "backbone.blocks.29.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.dense3.bias (2560,)\n",
      "backbone.blocks.29.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.29.output.mapping.bias (10240,)\n",
      "backbone.blocks.29.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.29.output.projection.bias (1310720,)\n",
      "backbone.blocks.30.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.30.layernorm1.beta (1310720,)\n",
      "backbone.blocks.30.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.30.layernorm2.beta (1310720,)\n",
      "backbone.blocks.30.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.projection.bias (1310720,)\n",
      "backbone.blocks.30.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.dense1.bias (2560,)\n",
      "backbone.blocks.30.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.dense2.bias (2560,)\n",
      "backbone.blocks.30.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.dense3.bias (2560,)\n",
      "backbone.blocks.30.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.30.output.mapping.bias (10240,)\n",
      "backbone.blocks.30.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.30.output.projection.bias (1310720,)\n",
      "backbone.layernorm.gamma (1310720,)\n",
      "backbone.layernorm.beta (1310720,)\n",
      "backbone.top_query_layer.layernorm1.gamma (1310720,)\n",
      "backbone.top_query_layer.layernorm1.beta (1310720,)\n",
      "backbone.top_query_layer.layernorm2.gamma (1310720,)\n",
      "backbone.top_query_layer.layernorm2.beta (1310720,)\n",
      "backbone.top_query_layer.attention.projection.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.projection.bias (1310720,)\n",
      "backbone.top_query_layer.attention.dense1.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.dense1.bias (2560,)\n",
      "backbone.top_query_layer.attention.dense2.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.dense2.bias (2560,)\n",
      "backbone.top_query_layer.attention.dense3.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.dense3.bias (2560,)\n",
      "backbone.top_query_layer.output.mapping.weight (20480, 1280)\n",
      "backbone.top_query_layer.output.mapping.bias (10240,)\n",
      "backbone.top_query_layer.output.projection.weight (10240, 2560)\n",
      "backbone.top_query_layer.output.projection.bias (1310720,)\n",
      "global_step (512,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in weights.items():\n",
    "    if hasattr(v, 'shape'):\n",
    "        print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2, 40000)\n"
     ]
    }
   ],
   "source": [
    "from models import TFPanGuAlphaLMHeadModel\n",
    "from transformers import GPT2Config\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=40000,\n",
    "    n_positions=1024,\n",
    "    n_ctx=1024,\n",
    "    n_embd=2560,\n",
    "    n_layer=31,\n",
    "    n_head=32\n",
    ")\n",
    "model = TFPanGuAlphaLMHeadModel(config)\n",
    "input = tf.constant([[1, 2]])\n",
    "out = model(input)[0]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "setting transformer/wpe/embeddings\n",
      "setting transformer/wte/weight\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_proj/bias:0\n",
      "setting transformer/ln_f/gamma\n",
      "setting transformer/ln_f/beta\n",
      "setting transformer/top_query_embedding\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_proj/bias:0\n",
      "(2560, 5120) (2560, 5120)\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn_query/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn_query/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_proj/bias:0\n",
      "[]\n",
      "391 391\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "new_weights = []\n",
    "\n",
    "download_path = '/home/mymusise/Downloads/pangu_model/'\n",
    "not_set = []\n",
    "for weight in model.weights:\n",
    "    num_layer = 0\n",
    "    if 'h_._' in weight.name:\n",
    "        num_layer = re.findall(r'transformer/h_._(\\d+)', weight.name)[0]\n",
    "        block_name = f\"backbone.blocks.{num_layer}\"\n",
    "    if 'top_query_layer' in weight.name:\n",
    "        block_name = 'backbone.top_query_layer'\n",
    "    \n",
    "    if 'transformer/wte/weight:0' in weight.name:\n",
    "        w = np.load(f\"{download_path}/word_embedding.npy\")\n",
    "        assert w.shape == (40000, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/wte/weight')\n",
    "    elif 'transformer/wpe/embeddings:0' in weight.name:\n",
    "        w = np.load(f\"{download_path}/position_embedding.npy\")\n",
    "        assert w.shape == (1024, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/wpe/embeddings')\n",
    "    elif 'top_query_embedding' in weight.name:\n",
    "        w = np.load(f\"{download_path}/top_query_embedding.npy\")\n",
    "        assert w.shape == (1024, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/top_query_embedding')\n",
    "    elif f'/ln_1/gamma:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm1.gamma')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif f'/ln_1/beta:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm1.beta')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "\n",
    "\n",
    "    ### normal transformer  ###\n",
    "    elif 'attn/c_attn/weight:0' in weight.name and 'top_query' not in weight.name:\n",
    "        query = get_weight(f'{block_name}.attention.dense1.weight')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.weight')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.weight')\n",
    "        w = np.concatenate([query, key, value], axis=1)\n",
    "        assert w.shape == (2560, 7680)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn/bias:0' in weight.name and 'top_query' not in weight.name:\n",
    "        query = get_weight(f'{block_name}.attention.dense1.bias')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.bias')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.bias')\n",
    "        w = np.concatenate([query, key, value], axis=0)\n",
    "        w = w.reshape(1,7680) # ???\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/weight:0' in weight.name and 'top_query' not in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.weight')\n",
    "        assert w.shape == (2560, 2560)\n",
    "        # w = np.transpose(w)  # ???\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/bias:0' in weight.name and 'top_query' not in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.bias')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        w = w.reshape(1, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "\n",
    "\n",
    "    ###  top_quert ###\n",
    "    elif 'attn/c_attn/weight:0' in weight.name and 'top_query' in weight.name:\n",
    "        # query = get_weight(f'{block_name}.attention.dense1.weight')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.weight')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.weight')\n",
    "        w = np.concatenate([key, value], axis=1)\n",
    "        assert w.shape == (2560, 2560 * 2)\n",
    "        print(w.shape, weight.shape)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn/bias:0' in weight.name and 'top_query' in weight.name:\n",
    "        # query = get_weight(f'{block_name}.attention.dense1.bias')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.bias')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.bias')\n",
    "        w = np.concatenate([key, value], axis=0)\n",
    "        w = w.reshape(1,2560 * 2)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn_query/weight:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.dense1.weight')\n",
    "        assert w.shape == (2560, 2560)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn_query/bias:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.dense1.bias')\n",
    "        w = w.reshape(1,2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/weight:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.weight')\n",
    "        assert w.shape == (2560, 2560)\n",
    "        # w = np.transpose(w)  # ???\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/bias:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.bias')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        w = w.reshape(1, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    ### top query ###\n",
    "\n",
    "\n",
    "    elif f'/ln_2/gamma:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm2.gamma')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif f'/ln_2/beta:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm2.beta')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_fc/weight:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.mapping.weight')\n",
    "        assert w.shape == (10240 * 2, 2560 /2)  # TODO: 这里很神奇，要检查下\n",
    "        w = np.reshape(w, (2560, 10240))\n",
    "        # assert w.shape == (10240, 2560)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_fc/bias:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.mapping.bias')\n",
    "        assert w.shape == (10240, )\n",
    "        w = w.reshape(1, 10240)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_proj/weight:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.projection.weight')\n",
    "        assert w.shape == (10240, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_proj/bias:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.projection.bias')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        w = w.reshape(1, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'transformer/ln_f/gamma:0' in weight.name:\n",
    "        w = get_weight(f'backbone.layernorm.gamma')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/ln_f/gamma')\n",
    "    elif 'transformer/ln_f/beta:0' in weight.name:\n",
    "        w = get_weight(f'backbone.layernorm.beta')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/ln_f/beta')\n",
    "    else:\n",
    "        not_set.append(weight.name)\n",
    "\n",
    "print(not_set)\n",
    "print(len(model.weights), len(new_weights))\n",
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "我的理想三四,,双特别<eot>就下2“,和上\n",
      "我的理想,的,,,,,的的\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, TFGPT2LMHeadModel\n",
    "# add spicel process \n",
    "class XLNetTokenizer(XLNetTokenizer):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "\n",
    "    def _tokenize(self, text, *args, **kwargs):\n",
    "        text = [x.translate(self.translator) for x in jieba.cut(text, cut_all=False)]\n",
    "        text = \" \".join(text)\n",
    "        return super()._tokenize(text, *args, **kwargs)\n",
    "\n",
    "    def _decode(self, *args, **kwargs):\n",
    "        text = super()._decode(*args, **kwargs)\n",
    "        text = text.replace(' ', '').replace('\\u2582', ' ').replace('\\u2583', '\\n')\n",
    "        return text\n",
    "\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('/data2/PanGu-Alpha')\n",
    "\n",
    "\n",
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "\n",
    "\n",
    "# class TextGenerationPipeline(TextGenerationPipeline):\n",
    "\n",
    "TextGenerationPipeline.ALLOWED_MODELS.append(\"TFPanGuAlphaLMHeadModel\")\n",
    "\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "texts = [\n",
    "    '我的理想',\n",
    "    # '天下武功, 唯快不',\n",
    "    # '天下熙熙,',\n",
    "    # '她腰间',\n",
    "    # \"\"\"\n",
    "    # 我们在火星上发现了大量的神奇物种。有神奇的海星兽，身上是粉色的，有5条腿；有胆小的猫猫兽，橘色，有4条腿；有令人恐惧的蜈蚣兽，全身漆黑，36条腿；有纯洁的天使兽，全身洁白无瑕，有3条腿；有贪吃的汪汪兽，银色的毛发，有5条腿；有蛋蛋兽，紫色，8条腿。\n",
    "\n",
    "    # 请根据上文，列出一个表格，包含物种名、颜色、腿数量。\n",
    "    # |物种名|颜色|腿数量|\n",
    "    # |亚古兽|金黄|2|\n",
    "    # |海星兽|粉色|5|\n",
    "    # |猫猫兽|橘色|4|\n",
    "    # |蜈蚣兽|漆黑|36|\n",
    "    # \"\"\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    token_len = len(tokenizer._tokenize(text))\n",
    "    # print(text_generater(text, max_length=token_len + 200, top_k=1, use_cache=True, prefix='')[0]['generated_text'])\n",
    "    print(text_generater(text, max_length=token_len + 16, do_sample=True, repetition_penalty=1.3)[0]['generated_text'])\n",
    "    print(text_generater(text, max_length=token_len + 16, do_sample=True, top_k=3)[0]['generated_text'])"
   ]
  }
 ]
}