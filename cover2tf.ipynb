{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "backbone.blocks.0.layernorm1.gamma\n",
      "backbone.blocks.0.layernorm1.beta\n",
      "backbone.blocks.0.layernorm2.gamma\n",
      "backbone.blocks.0.layernorm2.beta\n",
      "backbone.blocks.0.attention.projection.weight\n",
      "backbone.blocks.0.attention.projection.bias\n",
      "backbone.blocks.0.attention.dense1.weight\n",
      "backbone.blocks.0.attention.dense1.bias\n",
      "backbone.blocks.0.attention.dense2.weight\n",
      "backbone.blocks.0.attention.dense2.bias\n",
      "backbone.blocks.0.attention.dense3.weight\n",
      "backbone.blocks.0.attention.dense3.bias\n",
      "backbone.blocks.0.output.mapping.weight\n",
      "backbone.blocks.0.output.mapping.bias\n",
      "backbone.blocks.0.output.projection.weight\n",
      "backbone.blocks.0.output.projection.bias\n",
      "backbone.blocks.1.layernorm1.gamma\n",
      "backbone.blocks.1.layernorm1.beta\n",
      "backbone.blocks.1.layernorm2.gamma\n",
      "backbone.blocks.1.layernorm2.beta\n",
      "backbone.blocks.1.attention.projection.weight\n",
      "backbone.blocks.1.attention.projection.bias\n",
      "backbone.blocks.1.attention.dense1.weight\n",
      "backbone.blocks.1.attention.dense1.bias\n",
      "backbone.blocks.1.attention.dense2.weight\n",
      "backbone.blocks.1.attention.dense2.bias\n",
      "backbone.blocks.1.attention.dense3.weight\n",
      "backbone.blocks.1.attention.dense3.bias\n",
      "backbone.blocks.1.output.mapping.weight\n",
      "backbone.blocks.1.output.mapping.bias\n",
      "backbone.blocks.1.output.projection.weight\n",
      "backbone.blocks.1.output.projection.bias\n",
      "backbone.blocks.2.layernorm1.gamma\n",
      "backbone.blocks.2.layernorm1.beta\n",
      "backbone.blocks.2.layernorm2.gamma\n",
      "backbone.blocks.2.layernorm2.beta\n",
      "backbone.blocks.2.attention.projection.weight\n",
      "backbone.blocks.2.attention.projection.bias\n",
      "backbone.blocks.2.attention.dense1.weight\n",
      "backbone.blocks.2.attention.dense1.bias\n",
      "backbone.blocks.2.attention.dense2.weight\n",
      "backbone.blocks.2.attention.dense2.bias\n",
      "backbone.blocks.2.attention.dense3.weight\n",
      "backbone.blocks.2.attention.dense3.bias\n",
      "backbone.blocks.2.output.mapping.weight\n",
      "backbone.blocks.2.output.mapping.bias\n",
      "backbone.blocks.2.output.projection.weight\n",
      "backbone.blocks.2.output.projection.bias\n",
      "backbone.blocks.3.layernorm1.gamma\n",
      "backbone.blocks.3.layernorm1.beta\n",
      "backbone.blocks.3.layernorm2.gamma\n",
      "backbone.blocks.3.layernorm2.beta\n",
      "backbone.blocks.3.attention.projection.weight\n",
      "backbone.blocks.3.attention.projection.bias\n",
      "backbone.blocks.3.attention.dense1.weight\n",
      "backbone.blocks.3.attention.dense1.bias\n",
      "backbone.blocks.3.attention.dense2.weight\n",
      "backbone.blocks.3.attention.dense2.bias\n",
      "backbone.blocks.3.attention.dense3.weight\n",
      "backbone.blocks.3.attention.dense3.bias\n",
      "backbone.blocks.3.output.mapping.weight\n",
      "backbone.blocks.3.output.mapping.bias\n",
      "backbone.blocks.3.output.projection.weight\n",
      "backbone.blocks.3.output.projection.bias\n",
      "backbone.blocks.4.layernorm1.gamma\n",
      "backbone.blocks.4.layernorm1.beta\n",
      "backbone.blocks.4.layernorm2.gamma\n",
      "backbone.blocks.4.layernorm2.beta\n",
      "backbone.blocks.4.attention.projection.weight\n",
      "backbone.blocks.4.attention.projection.bias\n",
      "backbone.blocks.4.attention.dense1.weight\n",
      "backbone.blocks.4.attention.dense1.bias\n",
      "backbone.blocks.4.attention.dense2.weight\n",
      "backbone.blocks.4.attention.dense2.bias\n",
      "backbone.blocks.4.attention.dense3.weight\n",
      "backbone.blocks.4.attention.dense3.bias\n",
      "backbone.blocks.4.output.mapping.weight\n",
      "backbone.blocks.4.output.mapping.bias\n",
      "backbone.blocks.4.output.projection.weight\n",
      "backbone.blocks.4.output.projection.bias\n",
      "backbone.blocks.5.layernorm1.gamma\n",
      "backbone.blocks.5.layernorm1.beta\n",
      "backbone.blocks.5.layernorm2.gamma\n",
      "backbone.blocks.5.layernorm2.beta\n",
      "backbone.blocks.5.attention.projection.weight\n",
      "backbone.blocks.5.attention.projection.bias\n",
      "backbone.blocks.5.attention.dense1.weight\n",
      "backbone.blocks.5.attention.dense1.bias\n",
      "backbone.blocks.5.attention.dense2.weight\n",
      "backbone.blocks.5.attention.dense2.bias\n",
      "backbone.blocks.5.attention.dense3.weight\n",
      "backbone.blocks.5.attention.dense3.bias\n",
      "backbone.blocks.5.output.mapping.weight\n",
      "backbone.blocks.5.output.mapping.bias\n",
      "backbone.blocks.5.output.projection.weight\n",
      "backbone.blocks.5.output.projection.bias\n",
      "backbone.blocks.6.layernorm1.gamma\n",
      "backbone.blocks.6.layernorm1.beta\n",
      "backbone.blocks.6.layernorm2.gamma\n",
      "backbone.blocks.6.layernorm2.beta\n",
      "backbone.blocks.6.attention.projection.weight\n",
      "backbone.blocks.6.attention.projection.bias\n",
      "backbone.blocks.6.attention.dense1.weight\n",
      "backbone.blocks.6.attention.dense1.bias\n",
      "backbone.blocks.6.attention.dense2.weight\n",
      "backbone.blocks.6.attention.dense2.bias\n",
      "backbone.blocks.6.attention.dense3.weight\n",
      "backbone.blocks.6.attention.dense3.bias\n",
      "backbone.blocks.6.output.mapping.weight\n",
      "backbone.blocks.6.output.mapping.bias\n",
      "backbone.blocks.6.output.projection.weight\n",
      "backbone.blocks.6.output.projection.bias\n",
      "backbone.blocks.7.layernorm1.gamma\n",
      "backbone.blocks.7.layernorm1.beta\n",
      "backbone.blocks.7.layernorm2.gamma\n",
      "backbone.blocks.7.layernorm2.beta\n",
      "backbone.blocks.7.attention.projection.weight\n",
      "backbone.blocks.7.attention.projection.bias\n",
      "backbone.blocks.7.attention.dense1.weight\n",
      "backbone.blocks.7.attention.dense1.bias\n",
      "backbone.blocks.7.attention.dense2.weight\n",
      "backbone.blocks.7.attention.dense2.bias\n",
      "backbone.blocks.7.attention.dense3.weight\n",
      "backbone.blocks.7.attention.dense3.bias\n",
      "backbone.blocks.7.output.mapping.weight\n",
      "backbone.blocks.7.output.mapping.bias\n",
      "backbone.blocks.7.output.projection.weight\n",
      "backbone.blocks.7.output.projection.bias\n",
      "backbone.blocks.8.layernorm1.gamma\n",
      "backbone.blocks.8.layernorm1.beta\n",
      "backbone.blocks.8.layernorm2.gamma\n",
      "backbone.blocks.8.layernorm2.beta\n",
      "backbone.blocks.8.attention.projection.weight\n",
      "backbone.blocks.8.attention.projection.bias\n",
      "backbone.blocks.8.attention.dense1.weight\n",
      "backbone.blocks.8.attention.dense1.bias\n",
      "backbone.blocks.8.attention.dense2.weight\n",
      "backbone.blocks.8.attention.dense2.bias\n",
      "backbone.blocks.8.attention.dense3.weight\n",
      "backbone.blocks.8.attention.dense3.bias\n",
      "backbone.blocks.8.output.mapping.weight\n",
      "backbone.blocks.8.output.mapping.bias\n",
      "backbone.blocks.8.output.projection.weight\n",
      "backbone.blocks.8.output.projection.bias\n",
      "backbone.blocks.9.layernorm1.gamma\n",
      "backbone.blocks.9.layernorm1.beta\n",
      "backbone.blocks.9.layernorm2.gamma\n",
      "backbone.blocks.9.layernorm2.beta\n",
      "backbone.blocks.9.attention.projection.weight\n",
      "backbone.blocks.9.attention.projection.bias\n",
      "backbone.blocks.9.attention.dense1.weight\n",
      "backbone.blocks.9.attention.dense1.bias\n",
      "backbone.blocks.9.attention.dense2.weight\n",
      "backbone.blocks.9.attention.dense2.bias\n",
      "backbone.blocks.9.attention.dense3.weight\n",
      "backbone.blocks.9.attention.dense3.bias\n",
      "backbone.blocks.9.output.mapping.weight\n",
      "backbone.blocks.9.output.mapping.bias\n",
      "backbone.blocks.9.output.projection.weight\n",
      "backbone.blocks.9.output.projection.bias\n",
      "backbone.blocks.10.layernorm1.gamma\n",
      "backbone.blocks.10.layernorm1.beta\n",
      "backbone.blocks.10.layernorm2.gamma\n",
      "backbone.blocks.10.layernorm2.beta\n",
      "backbone.blocks.10.attention.projection.weight\n",
      "backbone.blocks.10.attention.projection.bias\n",
      "backbone.blocks.10.attention.dense1.weight\n",
      "backbone.blocks.10.attention.dense1.bias\n",
      "backbone.blocks.10.attention.dense2.weight\n",
      "backbone.blocks.10.attention.dense2.bias\n",
      "backbone.blocks.10.attention.dense3.weight\n",
      "backbone.blocks.10.attention.dense3.bias\n",
      "backbone.blocks.10.output.mapping.weight\n",
      "backbone.blocks.10.output.mapping.bias\n",
      "backbone.blocks.10.output.projection.weight\n",
      "backbone.blocks.10.output.projection.bias\n",
      "backbone.blocks.11.layernorm1.gamma\n",
      "backbone.blocks.11.layernorm1.beta\n",
      "backbone.blocks.11.layernorm2.gamma\n",
      "backbone.blocks.11.layernorm2.beta\n",
      "backbone.blocks.11.attention.projection.weight\n",
      "backbone.blocks.11.attention.projection.bias\n",
      "backbone.blocks.11.attention.dense1.weight\n",
      "backbone.blocks.11.attention.dense1.bias\n",
      "backbone.blocks.11.attention.dense2.weight\n",
      "backbone.blocks.11.attention.dense2.bias\n",
      "backbone.blocks.11.attention.dense3.weight\n",
      "backbone.blocks.11.attention.dense3.bias\n",
      "backbone.blocks.11.output.mapping.weight\n",
      "backbone.blocks.11.output.mapping.bias\n",
      "backbone.blocks.11.output.projection.weight\n",
      "backbone.blocks.11.output.projection.bias\n",
      "backbone.blocks.12.layernorm1.gamma\n",
      "backbone.blocks.12.layernorm1.beta\n",
      "backbone.blocks.12.layernorm2.gamma\n",
      "backbone.blocks.12.layernorm2.beta\n",
      "backbone.blocks.12.attention.projection.weight\n",
      "backbone.blocks.12.attention.projection.bias\n",
      "backbone.blocks.12.attention.dense1.weight\n",
      "backbone.blocks.12.attention.dense1.bias\n",
      "backbone.blocks.12.attention.dense2.weight\n",
      "backbone.blocks.12.attention.dense2.bias\n",
      "backbone.blocks.12.attention.dense3.weight\n",
      "backbone.blocks.12.attention.dense3.bias\n",
      "backbone.blocks.12.output.mapping.weight\n",
      "backbone.blocks.12.output.mapping.bias\n",
      "backbone.blocks.12.output.projection.weight\n",
      "backbone.blocks.12.output.projection.bias\n",
      "backbone.blocks.13.layernorm1.gamma\n",
      "backbone.blocks.13.layernorm1.beta\n",
      "backbone.blocks.13.layernorm2.gamma\n",
      "backbone.blocks.13.layernorm2.beta\n",
      "backbone.blocks.13.attention.projection.weight\n",
      "backbone.blocks.13.attention.projection.bias\n",
      "backbone.blocks.13.attention.dense1.weight\n",
      "backbone.blocks.13.attention.dense1.bias\n",
      "backbone.blocks.13.attention.dense2.weight\n",
      "backbone.blocks.13.attention.dense2.bias\n",
      "backbone.blocks.13.attention.dense3.weight\n",
      "backbone.blocks.13.attention.dense3.bias\n",
      "backbone.blocks.13.output.mapping.weight\n",
      "backbone.blocks.13.output.mapping.bias\n",
      "backbone.blocks.13.output.projection.weight\n",
      "backbone.blocks.13.output.projection.bias\n",
      "backbone.blocks.14.layernorm1.gamma\n",
      "backbone.blocks.14.layernorm1.beta\n",
      "backbone.blocks.14.layernorm2.gamma\n",
      "backbone.blocks.14.layernorm2.beta\n",
      "backbone.blocks.14.attention.projection.weight\n",
      "backbone.blocks.14.attention.projection.bias\n",
      "backbone.blocks.14.attention.dense1.weight\n",
      "backbone.blocks.14.attention.dense1.bias\n",
      "backbone.blocks.14.attention.dense2.weight\n",
      "backbone.blocks.14.attention.dense2.bias\n",
      "backbone.blocks.14.attention.dense3.weight\n",
      "backbone.blocks.14.attention.dense3.bias\n",
      "backbone.blocks.14.output.mapping.weight\n",
      "backbone.blocks.14.output.mapping.bias\n",
      "backbone.blocks.14.output.projection.weight\n",
      "backbone.blocks.14.output.projection.bias\n",
      "backbone.blocks.15.layernorm1.gamma\n",
      "backbone.blocks.15.layernorm1.beta\n",
      "backbone.blocks.15.layernorm2.gamma\n",
      "backbone.blocks.15.layernorm2.beta\n",
      "backbone.blocks.15.attention.projection.weight\n",
      "backbone.blocks.15.attention.projection.bias\n",
      "backbone.blocks.15.attention.dense1.weight\n",
      "backbone.blocks.15.attention.dense1.bias\n",
      "backbone.blocks.15.attention.dense2.weight\n",
      "backbone.blocks.15.attention.dense2.bias\n",
      "backbone.blocks.15.attention.dense3.weight\n",
      "backbone.blocks.15.attention.dense3.bias\n",
      "backbone.blocks.15.output.mapping.weight\n",
      "backbone.blocks.15.output.mapping.bias\n",
      "backbone.blocks.15.output.projection.weight\n",
      "backbone.blocks.15.output.projection.bias\n",
      "backbone.blocks.16.layernorm1.gamma\n",
      "backbone.blocks.16.layernorm1.beta\n",
      "backbone.blocks.16.layernorm2.gamma\n",
      "backbone.blocks.16.layernorm2.beta\n",
      "backbone.blocks.16.attention.projection.weight\n",
      "backbone.blocks.16.attention.projection.bias\n",
      "backbone.blocks.16.attention.dense1.weight\n",
      "backbone.blocks.16.attention.dense1.bias\n",
      "backbone.blocks.16.attention.dense2.weight\n",
      "backbone.blocks.16.attention.dense2.bias\n",
      "backbone.blocks.16.attention.dense3.weight\n",
      "backbone.blocks.16.attention.dense3.bias\n",
      "backbone.blocks.16.output.mapping.weight\n",
      "backbone.blocks.16.output.mapping.bias\n",
      "backbone.blocks.16.output.projection.weight\n",
      "backbone.blocks.16.output.projection.bias\n",
      "backbone.blocks.17.layernorm1.gamma\n",
      "backbone.blocks.17.layernorm1.beta\n",
      "backbone.blocks.17.layernorm2.gamma\n",
      "backbone.blocks.17.layernorm2.beta\n",
      "backbone.blocks.17.attention.projection.weight\n",
      "backbone.blocks.17.attention.projection.bias\n",
      "backbone.blocks.17.attention.dense1.weight\n",
      "backbone.blocks.17.attention.dense1.bias\n",
      "backbone.blocks.17.attention.dense2.weight\n",
      "backbone.blocks.17.attention.dense2.bias\n",
      "backbone.blocks.17.attention.dense3.weight\n",
      "backbone.blocks.17.attention.dense3.bias\n",
      "backbone.blocks.17.output.mapping.weight\n",
      "backbone.blocks.17.output.mapping.bias\n",
      "backbone.blocks.17.output.projection.weight\n",
      "backbone.blocks.17.output.projection.bias\n",
      "backbone.blocks.18.layernorm1.gamma\n",
      "backbone.blocks.18.layernorm1.beta\n",
      "backbone.blocks.18.layernorm2.gamma\n",
      "backbone.blocks.18.layernorm2.beta\n",
      "backbone.blocks.18.attention.projection.weight\n",
      "backbone.blocks.18.attention.projection.bias\n",
      "backbone.blocks.18.attention.dense1.weight\n",
      "backbone.blocks.18.attention.dense1.bias\n",
      "backbone.blocks.18.attention.dense2.weight\n",
      "backbone.blocks.18.attention.dense2.bias\n",
      "backbone.blocks.18.attention.dense3.weight\n",
      "backbone.blocks.18.attention.dense3.bias\n",
      "backbone.blocks.18.output.mapping.weight\n",
      "backbone.blocks.18.output.mapping.bias\n",
      "backbone.blocks.18.output.projection.weight\n",
      "backbone.blocks.18.output.projection.bias\n",
      "backbone.blocks.19.layernorm1.gamma\n",
      "backbone.blocks.19.layernorm1.beta\n",
      "backbone.blocks.19.layernorm2.gamma\n",
      "backbone.blocks.19.layernorm2.beta\n",
      "backbone.blocks.19.attention.projection.weight\n",
      "backbone.blocks.19.attention.projection.bias\n",
      "backbone.blocks.19.attention.dense1.weight\n",
      "backbone.blocks.19.attention.dense1.bias\n",
      "backbone.blocks.19.attention.dense2.weight\n",
      "backbone.blocks.19.attention.dense2.bias\n",
      "backbone.blocks.19.attention.dense3.weight\n",
      "backbone.blocks.19.attention.dense3.bias\n",
      "backbone.blocks.19.output.mapping.weight\n",
      "backbone.blocks.19.output.mapping.bias\n",
      "backbone.blocks.19.output.projection.weight\n",
      "backbone.blocks.19.output.projection.bias\n",
      "backbone.blocks.20.layernorm1.gamma\n",
      "backbone.blocks.20.layernorm1.beta\n",
      "backbone.blocks.20.layernorm2.gamma\n",
      "backbone.blocks.20.layernorm2.beta\n",
      "backbone.blocks.20.attention.projection.weight\n",
      "backbone.blocks.20.attention.projection.bias\n",
      "backbone.blocks.20.attention.dense1.weight\n",
      "backbone.blocks.20.attention.dense1.bias\n",
      "backbone.blocks.20.attention.dense2.weight\n",
      "backbone.blocks.20.attention.dense2.bias\n",
      "backbone.blocks.20.attention.dense3.weight\n",
      "backbone.blocks.20.attention.dense3.bias\n",
      "backbone.blocks.20.output.mapping.weight\n",
      "backbone.blocks.20.output.mapping.bias\n",
      "backbone.blocks.20.output.projection.weight\n",
      "backbone.blocks.20.output.projection.bias\n",
      "backbone.blocks.21.layernorm1.gamma\n",
      "backbone.blocks.21.layernorm1.beta\n",
      "backbone.blocks.21.layernorm2.gamma\n",
      "backbone.blocks.21.layernorm2.beta\n",
      "backbone.blocks.21.attention.projection.weight\n",
      "backbone.blocks.21.attention.projection.bias\n",
      "backbone.blocks.21.attention.dense1.weight\n",
      "backbone.blocks.21.attention.dense1.bias\n",
      "backbone.blocks.21.attention.dense2.weight\n",
      "backbone.blocks.21.attention.dense2.bias\n",
      "backbone.blocks.21.attention.dense3.weight\n",
      "backbone.blocks.21.attention.dense3.bias\n",
      "backbone.blocks.21.output.mapping.weight\n",
      "backbone.blocks.21.output.mapping.bias\n",
      "backbone.blocks.21.output.projection.weight\n",
      "backbone.blocks.21.output.projection.bias\n",
      "backbone.blocks.22.layernorm1.gamma\n",
      "backbone.blocks.22.layernorm1.beta\n",
      "backbone.blocks.22.layernorm2.gamma\n",
      "backbone.blocks.22.layernorm2.beta\n",
      "backbone.blocks.22.attention.projection.weight\n",
      "backbone.blocks.22.attention.projection.bias\n",
      "backbone.blocks.22.attention.dense1.weight\n",
      "backbone.blocks.22.attention.dense1.bias\n",
      "backbone.blocks.22.attention.dense2.weight\n",
      "backbone.blocks.22.attention.dense2.bias\n",
      "backbone.blocks.22.attention.dense3.weight\n",
      "backbone.blocks.22.attention.dense3.bias\n",
      "backbone.blocks.22.output.mapping.weight\n",
      "backbone.blocks.22.output.mapping.bias\n",
      "backbone.blocks.22.output.projection.weight\n",
      "backbone.blocks.22.output.projection.bias\n",
      "backbone.blocks.23.layernorm1.gamma\n",
      "backbone.blocks.23.layernorm1.beta\n",
      "backbone.blocks.23.layernorm2.gamma\n",
      "backbone.blocks.23.layernorm2.beta\n",
      "backbone.blocks.23.attention.projection.weight\n",
      "backbone.blocks.23.attention.projection.bias\n",
      "backbone.blocks.23.attention.dense1.weight\n",
      "backbone.blocks.23.attention.dense1.bias\n",
      "backbone.blocks.23.attention.dense2.weight\n",
      "backbone.blocks.23.attention.dense2.bias\n",
      "backbone.blocks.23.attention.dense3.weight\n",
      "backbone.blocks.23.attention.dense3.bias\n",
      "backbone.blocks.23.output.mapping.weight\n",
      "backbone.blocks.23.output.mapping.bias\n",
      "backbone.blocks.23.output.projection.weight\n",
      "backbone.blocks.23.output.projection.bias\n",
      "backbone.blocks.24.layernorm1.gamma\n",
      "backbone.blocks.24.layernorm1.beta\n",
      "backbone.blocks.24.layernorm2.gamma\n",
      "backbone.blocks.24.layernorm2.beta\n",
      "backbone.blocks.24.attention.projection.weight\n",
      "backbone.blocks.24.attention.projection.bias\n",
      "backbone.blocks.24.attention.dense1.weight\n",
      "backbone.blocks.24.attention.dense1.bias\n",
      "backbone.blocks.24.attention.dense2.weight\n",
      "backbone.blocks.24.attention.dense2.bias\n",
      "backbone.blocks.24.attention.dense3.weight\n",
      "backbone.blocks.24.attention.dense3.bias\n",
      "backbone.blocks.24.output.mapping.weight\n",
      "backbone.blocks.24.output.mapping.bias\n",
      "backbone.blocks.24.output.projection.weight\n",
      "backbone.blocks.24.output.projection.bias\n",
      "backbone.blocks.25.layernorm1.gamma\n",
      "backbone.blocks.25.layernorm1.beta\n",
      "backbone.blocks.25.layernorm2.gamma\n",
      "backbone.blocks.25.layernorm2.beta\n",
      "backbone.blocks.25.attention.projection.weight\n",
      "backbone.blocks.25.attention.projection.bias\n",
      "backbone.blocks.25.attention.dense1.weight\n",
      "backbone.blocks.25.attention.dense1.bias\n",
      "backbone.blocks.25.attention.dense2.weight\n",
      "backbone.blocks.25.attention.dense2.bias\n",
      "backbone.blocks.25.attention.dense3.weight\n",
      "backbone.blocks.25.attention.dense3.bias\n",
      "backbone.blocks.25.output.mapping.weight\n",
      "backbone.blocks.25.output.mapping.bias\n",
      "backbone.blocks.25.output.projection.weight\n",
      "backbone.blocks.25.output.projection.bias\n",
      "backbone.blocks.26.layernorm1.gamma\n",
      "backbone.blocks.26.layernorm1.beta\n",
      "backbone.blocks.26.layernorm2.gamma\n",
      "backbone.blocks.26.layernorm2.beta\n",
      "backbone.blocks.26.attention.projection.weight\n",
      "backbone.blocks.26.attention.projection.bias\n",
      "backbone.blocks.26.attention.dense1.weight\n",
      "backbone.blocks.26.attention.dense1.bias\n",
      "backbone.blocks.26.attention.dense2.weight\n",
      "backbone.blocks.26.attention.dense2.bias\n",
      "backbone.blocks.26.attention.dense3.weight\n",
      "backbone.blocks.26.attention.dense3.bias\n",
      "backbone.blocks.26.output.mapping.weight\n",
      "backbone.blocks.26.output.mapping.bias\n",
      "backbone.blocks.26.output.projection.weight\n",
      "backbone.blocks.26.output.projection.bias\n",
      "backbone.blocks.27.layernorm1.gamma\n",
      "backbone.blocks.27.layernorm1.beta\n",
      "backbone.blocks.27.layernorm2.gamma\n",
      "backbone.blocks.27.layernorm2.beta\n",
      "backbone.blocks.27.attention.projection.weight\n",
      "backbone.blocks.27.attention.projection.bias\n",
      "backbone.blocks.27.attention.dense1.weight\n",
      "backbone.blocks.27.attention.dense1.bias\n",
      "backbone.blocks.27.attention.dense2.weight\n",
      "backbone.blocks.27.attention.dense2.bias\n",
      "backbone.blocks.27.attention.dense3.weight\n",
      "backbone.blocks.27.attention.dense3.bias\n",
      "backbone.blocks.27.output.mapping.weight\n",
      "backbone.blocks.27.output.mapping.bias\n",
      "backbone.blocks.27.output.projection.weight\n",
      "backbone.blocks.27.output.projection.bias\n",
      "backbone.blocks.28.layernorm1.gamma\n",
      "backbone.blocks.28.layernorm1.beta\n",
      "backbone.blocks.28.layernorm2.gamma\n",
      "backbone.blocks.28.layernorm2.beta\n",
      "backbone.blocks.28.attention.projection.weight\n",
      "backbone.blocks.28.attention.projection.bias\n",
      "backbone.blocks.28.attention.dense1.weight\n",
      "backbone.blocks.28.attention.dense1.bias\n",
      "backbone.blocks.28.attention.dense2.weight\n",
      "backbone.blocks.28.attention.dense2.bias\n",
      "backbone.blocks.28.attention.dense3.weight\n",
      "backbone.blocks.28.attention.dense3.bias\n",
      "backbone.blocks.28.output.mapping.weight\n",
      "backbone.blocks.28.output.mapping.bias\n",
      "backbone.blocks.28.output.projection.weight\n",
      "backbone.blocks.28.output.projection.bias\n",
      "backbone.blocks.29.layernorm1.gamma\n",
      "backbone.blocks.29.layernorm1.beta\n",
      "backbone.blocks.29.layernorm2.gamma\n",
      "backbone.blocks.29.layernorm2.beta\n",
      "backbone.blocks.29.attention.projection.weight\n",
      "backbone.blocks.29.attention.projection.bias\n",
      "backbone.blocks.29.attention.dense1.weight\n",
      "backbone.blocks.29.attention.dense1.bias\n",
      "backbone.blocks.29.attention.dense2.weight\n",
      "backbone.blocks.29.attention.dense2.bias\n",
      "backbone.blocks.29.attention.dense3.weight\n",
      "backbone.blocks.29.attention.dense3.bias\n",
      "backbone.blocks.29.output.mapping.weight\n",
      "backbone.blocks.29.output.mapping.bias\n",
      "backbone.blocks.29.output.projection.weight\n",
      "backbone.blocks.29.output.projection.bias\n",
      "backbone.blocks.30.layernorm1.gamma\n",
      "backbone.blocks.30.layernorm1.beta\n",
      "backbone.blocks.30.layernorm2.gamma\n",
      "backbone.blocks.30.layernorm2.beta\n",
      "backbone.blocks.30.attention.projection.weight\n",
      "backbone.blocks.30.attention.projection.bias\n",
      "backbone.blocks.30.attention.dense1.weight\n",
      "backbone.blocks.30.attention.dense1.bias\n",
      "backbone.blocks.30.attention.dense2.weight\n",
      "backbone.blocks.30.attention.dense2.bias\n",
      "backbone.blocks.30.attention.dense3.weight\n",
      "backbone.blocks.30.attention.dense3.bias\n",
      "backbone.blocks.30.output.mapping.weight\n",
      "backbone.blocks.30.output.mapping.bias\n",
      "backbone.blocks.30.output.projection.weight\n",
      "backbone.blocks.30.output.projection.bias\n",
      "backbone.layernorm.gamma\n",
      "backbone.layernorm.beta\n",
      "backbone.top_query_layer.layernorm1.gamma\n",
      "backbone.top_query_layer.layernorm1.beta\n",
      "backbone.top_query_layer.layernorm2.gamma\n",
      "backbone.top_query_layer.layernorm2.beta\n",
      "backbone.top_query_layer.attention.projection.weight\n",
      "backbone.top_query_layer.attention.projection.bias\n",
      "backbone.top_query_layer.attention.dense1.weight\n",
      "backbone.top_query_layer.attention.dense1.bias\n",
      "backbone.top_query_layer.attention.dense2.weight\n",
      "backbone.top_query_layer.attention.dense2.bias\n",
      "backbone.top_query_layer.attention.dense3.weight\n",
      "backbone.top_query_layer.attention.dense3.bias\n",
      "backbone.top_query_layer.output.mapping.weight\n",
      "backbone.top_query_layer.output.mapping.bias\n",
      "backbone.top_query_layer.output.projection.weight\n",
      "backbone.top_query_layer.output.projection.bias\n",
      "loss_scale\n",
      "global_step\n",
      "current_iterator_step\n",
      "last_overflow_iterator_step\n",
      "has_trained_step\n",
      "cur_epoch_num\n",
      "has_trained_epoch\n",
      "data_start_index\n",
      "cur_step_num\n",
      "loss_scale_value\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "out_path = \"/home/mymusise/Downloads/pangu_model/numpy_weights\"\n",
    "\n",
    "path = Path(out_path)\n",
    "\n",
    "files = path.glob('*.pickle')\n",
    "files = sorted(list(files), key=lambda x:x.stat().st_mtime)\n",
    "\n",
    "weights = {}\n",
    "\n",
    "for f in files:\n",
    "    f = str(f)\n",
    "    key = f.split('/')[-1]\n",
    "    keys = key.split('.')[:-1]\n",
    "    key = \".\".join(keys)\n",
    "    print(key)\n",
    "    with open(f, 'rb') as f:\n",
    "        w_list = pickle.load(f)\n",
    "        if type(w_list[0]) == np.ndarray and w_list[0].shape:                \n",
    "            w_list = np.concatenate(w_list, axis=0)\n",
    "        weights[key] = w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(name):\n",
    "    for key in weights.keys():\n",
    "        if name in key:\n",
    "            return weights[key]\n",
    "\n",
    "# print(get_weight(f'{block_name}.layernorm1.gamma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "backbone.blocks.0.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.0.layernorm1.beta (1310720,)\n",
      "backbone.blocks.0.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.0.layernorm2.beta (1310720,)\n",
      "backbone.blocks.0.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.projection.bias (1310720,)\n",
      "backbone.blocks.0.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.dense1.bias (2560,)\n",
      "backbone.blocks.0.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.dense2.bias (2560,)\n",
      "backbone.blocks.0.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.0.attention.dense3.bias (2560,)\n",
      "backbone.blocks.0.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.0.output.mapping.bias (10240,)\n",
      "backbone.blocks.0.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.0.output.projection.bias (1310720,)\n",
      "backbone.blocks.1.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.1.layernorm1.beta (1310720,)\n",
      "backbone.blocks.1.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.1.layernorm2.beta (1310720,)\n",
      "backbone.blocks.1.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.projection.bias (1310720,)\n",
      "backbone.blocks.1.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.dense1.bias (2560,)\n",
      "backbone.blocks.1.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.dense2.bias (2560,)\n",
      "backbone.blocks.1.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.1.attention.dense3.bias (2560,)\n",
      "backbone.blocks.1.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.1.output.mapping.bias (10240,)\n",
      "backbone.blocks.1.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.1.output.projection.bias (1310720,)\n",
      "backbone.blocks.2.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.2.layernorm1.beta (1310720,)\n",
      "backbone.blocks.2.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.2.layernorm2.beta (1310720,)\n",
      "backbone.blocks.2.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.projection.bias (1310720,)\n",
      "backbone.blocks.2.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.dense1.bias (2560,)\n",
      "backbone.blocks.2.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.dense2.bias (2560,)\n",
      "backbone.blocks.2.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.2.attention.dense3.bias (2560,)\n",
      "backbone.blocks.2.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.2.output.mapping.bias (10240,)\n",
      "backbone.blocks.2.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.2.output.projection.bias (1310720,)\n",
      "backbone.blocks.3.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.3.layernorm1.beta (1310720,)\n",
      "backbone.blocks.3.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.3.layernorm2.beta (1310720,)\n",
      "backbone.blocks.3.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.projection.bias (1310720,)\n",
      "backbone.blocks.3.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.dense1.bias (2560,)\n",
      "backbone.blocks.3.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.dense2.bias (2560,)\n",
      "backbone.blocks.3.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.3.attention.dense3.bias (2560,)\n",
      "backbone.blocks.3.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.3.output.mapping.bias (10240,)\n",
      "backbone.blocks.3.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.3.output.projection.bias (1310720,)\n",
      "backbone.blocks.4.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.4.layernorm1.beta (1310720,)\n",
      "backbone.blocks.4.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.4.layernorm2.beta (1310720,)\n",
      "backbone.blocks.4.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.projection.bias (1310720,)\n",
      "backbone.blocks.4.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.dense1.bias (2560,)\n",
      "backbone.blocks.4.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.dense2.bias (2560,)\n",
      "backbone.blocks.4.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.4.attention.dense3.bias (2560,)\n",
      "backbone.blocks.4.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.4.output.mapping.bias (10240,)\n",
      "backbone.blocks.4.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.4.output.projection.bias (1310720,)\n",
      "backbone.blocks.5.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.5.layernorm1.beta (1310720,)\n",
      "backbone.blocks.5.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.5.layernorm2.beta (1310720,)\n",
      "backbone.blocks.5.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.projection.bias (1310720,)\n",
      "backbone.blocks.5.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.dense1.bias (2560,)\n",
      "backbone.blocks.5.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.dense2.bias (2560,)\n",
      "backbone.blocks.5.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.5.attention.dense3.bias (2560,)\n",
      "backbone.blocks.5.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.5.output.mapping.bias (10240,)\n",
      "backbone.blocks.5.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.5.output.projection.bias (1310720,)\n",
      "backbone.blocks.6.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.6.layernorm1.beta (1310720,)\n",
      "backbone.blocks.6.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.6.layernorm2.beta (1310720,)\n",
      "backbone.blocks.6.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.projection.bias (1310720,)\n",
      "backbone.blocks.6.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.dense1.bias (2560,)\n",
      "backbone.blocks.6.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.dense2.bias (2560,)\n",
      "backbone.blocks.6.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.6.attention.dense3.bias (2560,)\n",
      "backbone.blocks.6.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.6.output.mapping.bias (10240,)\n",
      "backbone.blocks.6.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.6.output.projection.bias (1310720,)\n",
      "backbone.blocks.7.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.7.layernorm1.beta (1310720,)\n",
      "backbone.blocks.7.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.7.layernorm2.beta (1310720,)\n",
      "backbone.blocks.7.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.projection.bias (1310720,)\n",
      "backbone.blocks.7.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.dense1.bias (2560,)\n",
      "backbone.blocks.7.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.dense2.bias (2560,)\n",
      "backbone.blocks.7.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.7.attention.dense3.bias (2560,)\n",
      "backbone.blocks.7.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.7.output.mapping.bias (10240,)\n",
      "backbone.blocks.7.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.7.output.projection.bias (1310720,)\n",
      "backbone.blocks.8.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.8.layernorm1.beta (1310720,)\n",
      "backbone.blocks.8.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.8.layernorm2.beta (1310720,)\n",
      "backbone.blocks.8.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.projection.bias (1310720,)\n",
      "backbone.blocks.8.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.dense1.bias (2560,)\n",
      "backbone.blocks.8.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.dense2.bias (2560,)\n",
      "backbone.blocks.8.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.8.attention.dense3.bias (2560,)\n",
      "backbone.blocks.8.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.8.output.mapping.bias (10240,)\n",
      "backbone.blocks.8.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.8.output.projection.bias (1310720,)\n",
      "backbone.blocks.9.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.9.layernorm1.beta (1310720,)\n",
      "backbone.blocks.9.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.9.layernorm2.beta (1310720,)\n",
      "backbone.blocks.9.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.projection.bias (1310720,)\n",
      "backbone.blocks.9.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.dense1.bias (2560,)\n",
      "backbone.blocks.9.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.dense2.bias (2560,)\n",
      "backbone.blocks.9.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.9.attention.dense3.bias (2560,)\n",
      "backbone.blocks.9.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.9.output.mapping.bias (10240,)\n",
      "backbone.blocks.9.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.9.output.projection.bias (1310720,)\n",
      "backbone.blocks.10.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.10.layernorm1.beta (1310720,)\n",
      "backbone.blocks.10.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.10.layernorm2.beta (1310720,)\n",
      "backbone.blocks.10.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.projection.bias (1310720,)\n",
      "backbone.blocks.10.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.dense1.bias (2560,)\n",
      "backbone.blocks.10.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.dense2.bias (2560,)\n",
      "backbone.blocks.10.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.10.attention.dense3.bias (2560,)\n",
      "backbone.blocks.10.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.10.output.mapping.bias (10240,)\n",
      "backbone.blocks.10.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.10.output.projection.bias (1310720,)\n",
      "backbone.blocks.11.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.11.layernorm1.beta (1310720,)\n",
      "backbone.blocks.11.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.11.layernorm2.beta (1310720,)\n",
      "backbone.blocks.11.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.projection.bias (1310720,)\n",
      "backbone.blocks.11.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.dense1.bias (2560,)\n",
      "backbone.blocks.11.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.dense2.bias (2560,)\n",
      "backbone.blocks.11.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.11.attention.dense3.bias (2560,)\n",
      "backbone.blocks.11.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.11.output.mapping.bias (10240,)\n",
      "backbone.blocks.11.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.11.output.projection.bias (1310720,)\n",
      "backbone.blocks.12.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.12.layernorm1.beta (1310720,)\n",
      "backbone.blocks.12.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.12.layernorm2.beta (1310720,)\n",
      "backbone.blocks.12.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.projection.bias (1310720,)\n",
      "backbone.blocks.12.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.dense1.bias (2560,)\n",
      "backbone.blocks.12.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.dense2.bias (2560,)\n",
      "backbone.blocks.12.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.12.attention.dense3.bias (2560,)\n",
      "backbone.blocks.12.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.12.output.mapping.bias (10240,)\n",
      "backbone.blocks.12.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.12.output.projection.bias (1310720,)\n",
      "backbone.blocks.13.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.13.layernorm1.beta (1310720,)\n",
      "backbone.blocks.13.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.13.layernorm2.beta (1310720,)\n",
      "backbone.blocks.13.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.projection.bias (1310720,)\n",
      "backbone.blocks.13.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.dense1.bias (2560,)\n",
      "backbone.blocks.13.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.dense2.bias (2560,)\n",
      "backbone.blocks.13.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.13.attention.dense3.bias (2560,)\n",
      "backbone.blocks.13.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.13.output.mapping.bias (10240,)\n",
      "backbone.blocks.13.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.13.output.projection.bias (1310720,)\n",
      "backbone.blocks.14.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.14.layernorm1.beta (1310720,)\n",
      "backbone.blocks.14.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.14.layernorm2.beta (1310720,)\n",
      "backbone.blocks.14.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.projection.bias (1310720,)\n",
      "backbone.blocks.14.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.dense1.bias (2560,)\n",
      "backbone.blocks.14.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.dense2.bias (2560,)\n",
      "backbone.blocks.14.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.14.attention.dense3.bias (2560,)\n",
      "backbone.blocks.14.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.14.output.mapping.bias (10240,)\n",
      "backbone.blocks.14.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.14.output.projection.bias (1310720,)\n",
      "backbone.blocks.15.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.15.layernorm1.beta (1310720,)\n",
      "backbone.blocks.15.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.15.layernorm2.beta (1310720,)\n",
      "backbone.blocks.15.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.projection.bias (1310720,)\n",
      "backbone.blocks.15.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.dense1.bias (2560,)\n",
      "backbone.blocks.15.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.dense2.bias (2560,)\n",
      "backbone.blocks.15.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.15.attention.dense3.bias (2560,)\n",
      "backbone.blocks.15.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.15.output.mapping.bias (10240,)\n",
      "backbone.blocks.15.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.15.output.projection.bias (1310720,)\n",
      "backbone.blocks.16.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.16.layernorm1.beta (1310720,)\n",
      "backbone.blocks.16.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.16.layernorm2.beta (1310720,)\n",
      "backbone.blocks.16.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.projection.bias (1310720,)\n",
      "backbone.blocks.16.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.dense1.bias (2560,)\n",
      "backbone.blocks.16.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.dense2.bias (2560,)\n",
      "backbone.blocks.16.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.16.attention.dense3.bias (2560,)\n",
      "backbone.blocks.16.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.16.output.mapping.bias (10240,)\n",
      "backbone.blocks.16.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.16.output.projection.bias (1310720,)\n",
      "backbone.blocks.17.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.17.layernorm1.beta (1310720,)\n",
      "backbone.blocks.17.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.17.layernorm2.beta (1310720,)\n",
      "backbone.blocks.17.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.projection.bias (1310720,)\n",
      "backbone.blocks.17.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.dense1.bias (2560,)\n",
      "backbone.blocks.17.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.dense2.bias (2560,)\n",
      "backbone.blocks.17.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.17.attention.dense3.bias (2560,)\n",
      "backbone.blocks.17.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.17.output.mapping.bias (10240,)\n",
      "backbone.blocks.17.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.17.output.projection.bias (1310720,)\n",
      "backbone.blocks.18.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.18.layernorm1.beta (1310720,)\n",
      "backbone.blocks.18.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.18.layernorm2.beta (1310720,)\n",
      "backbone.blocks.18.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.projection.bias (1310720,)\n",
      "backbone.blocks.18.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.dense1.bias (2560,)\n",
      "backbone.blocks.18.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.dense2.bias (2560,)\n",
      "backbone.blocks.18.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.18.attention.dense3.bias (2560,)\n",
      "backbone.blocks.18.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.18.output.mapping.bias (10240,)\n",
      "backbone.blocks.18.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.18.output.projection.bias (1310720,)\n",
      "backbone.blocks.19.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.19.layernorm1.beta (1310720,)\n",
      "backbone.blocks.19.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.19.layernorm2.beta (1310720,)\n",
      "backbone.blocks.19.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.projection.bias (1310720,)\n",
      "backbone.blocks.19.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.dense1.bias (2560,)\n",
      "backbone.blocks.19.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.dense2.bias (2560,)\n",
      "backbone.blocks.19.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.19.attention.dense3.bias (2560,)\n",
      "backbone.blocks.19.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.19.output.mapping.bias (10240,)\n",
      "backbone.blocks.19.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.19.output.projection.bias (1310720,)\n",
      "backbone.blocks.20.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.20.layernorm1.beta (1310720,)\n",
      "backbone.blocks.20.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.20.layernorm2.beta (1310720,)\n",
      "backbone.blocks.20.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.projection.bias (1310720,)\n",
      "backbone.blocks.20.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.dense1.bias (2560,)\n",
      "backbone.blocks.20.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.dense2.bias (2560,)\n",
      "backbone.blocks.20.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.20.attention.dense3.bias (2560,)\n",
      "backbone.blocks.20.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.20.output.mapping.bias (10240,)\n",
      "backbone.blocks.20.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.20.output.projection.bias (1310720,)\n",
      "backbone.blocks.21.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.21.layernorm1.beta (1310720,)\n",
      "backbone.blocks.21.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.21.layernorm2.beta (1310720,)\n",
      "backbone.blocks.21.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.projection.bias (1310720,)\n",
      "backbone.blocks.21.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.dense1.bias (2560,)\n",
      "backbone.blocks.21.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.dense2.bias (2560,)\n",
      "backbone.blocks.21.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.21.attention.dense3.bias (2560,)\n",
      "backbone.blocks.21.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.21.output.mapping.bias (10240,)\n",
      "backbone.blocks.21.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.21.output.projection.bias (1310720,)\n",
      "backbone.blocks.22.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.22.layernorm1.beta (1310720,)\n",
      "backbone.blocks.22.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.22.layernorm2.beta (1310720,)\n",
      "backbone.blocks.22.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.projection.bias (1310720,)\n",
      "backbone.blocks.22.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.dense1.bias (2560,)\n",
      "backbone.blocks.22.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.dense2.bias (2560,)\n",
      "backbone.blocks.22.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.22.attention.dense3.bias (2560,)\n",
      "backbone.blocks.22.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.22.output.mapping.bias (10240,)\n",
      "backbone.blocks.22.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.22.output.projection.bias (1310720,)\n",
      "backbone.blocks.23.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.23.layernorm1.beta (1310720,)\n",
      "backbone.blocks.23.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.23.layernorm2.beta (1310720,)\n",
      "backbone.blocks.23.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.projection.bias (1310720,)\n",
      "backbone.blocks.23.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.dense1.bias (2560,)\n",
      "backbone.blocks.23.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.dense2.bias (2560,)\n",
      "backbone.blocks.23.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.23.attention.dense3.bias (2560,)\n",
      "backbone.blocks.23.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.23.output.mapping.bias (10240,)\n",
      "backbone.blocks.23.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.23.output.projection.bias (1310720,)\n",
      "backbone.blocks.24.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.24.layernorm1.beta (1310720,)\n",
      "backbone.blocks.24.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.24.layernorm2.beta (1310720,)\n",
      "backbone.blocks.24.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.projection.bias (1310720,)\n",
      "backbone.blocks.24.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.dense1.bias (2560,)\n",
      "backbone.blocks.24.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.dense2.bias (2560,)\n",
      "backbone.blocks.24.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.24.attention.dense3.bias (2560,)\n",
      "backbone.blocks.24.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.24.output.mapping.bias (10240,)\n",
      "backbone.blocks.24.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.24.output.projection.bias (1310720,)\n",
      "backbone.blocks.25.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.25.layernorm1.beta (1310720,)\n",
      "backbone.blocks.25.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.25.layernorm2.beta (1310720,)\n",
      "backbone.blocks.25.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.projection.bias (1310720,)\n",
      "backbone.blocks.25.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.dense1.bias (2560,)\n",
      "backbone.blocks.25.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.dense2.bias (2560,)\n",
      "backbone.blocks.25.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.25.attention.dense3.bias (2560,)\n",
      "backbone.blocks.25.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.25.output.mapping.bias (10240,)\n",
      "backbone.blocks.25.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.25.output.projection.bias (1310720,)\n",
      "backbone.blocks.26.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.26.layernorm1.beta (1310720,)\n",
      "backbone.blocks.26.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.26.layernorm2.beta (1310720,)\n",
      "backbone.blocks.26.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.projection.bias (1310720,)\n",
      "backbone.blocks.26.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.dense1.bias (2560,)\n",
      "backbone.blocks.26.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.dense2.bias (2560,)\n",
      "backbone.blocks.26.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.26.attention.dense3.bias (2560,)\n",
      "backbone.blocks.26.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.26.output.mapping.bias (10240,)\n",
      "backbone.blocks.26.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.26.output.projection.bias (1310720,)\n",
      "backbone.blocks.27.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.27.layernorm1.beta (1310720,)\n",
      "backbone.blocks.27.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.27.layernorm2.beta (1310720,)\n",
      "backbone.blocks.27.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.projection.bias (1310720,)\n",
      "backbone.blocks.27.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.dense1.bias (2560,)\n",
      "backbone.blocks.27.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.dense2.bias (2560,)\n",
      "backbone.blocks.27.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.27.attention.dense3.bias (2560,)\n",
      "backbone.blocks.27.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.27.output.mapping.bias (10240,)\n",
      "backbone.blocks.27.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.27.output.projection.bias (1310720,)\n",
      "backbone.blocks.28.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.28.layernorm1.beta (1310720,)\n",
      "backbone.blocks.28.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.28.layernorm2.beta (1310720,)\n",
      "backbone.blocks.28.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.projection.bias (1310720,)\n",
      "backbone.blocks.28.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.dense1.bias (2560,)\n",
      "backbone.blocks.28.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.dense2.bias (2560,)\n",
      "backbone.blocks.28.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.28.attention.dense3.bias (2560,)\n",
      "backbone.blocks.28.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.28.output.mapping.bias (10240,)\n",
      "backbone.blocks.28.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.28.output.projection.bias (1310720,)\n",
      "backbone.blocks.29.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.29.layernorm1.beta (1310720,)\n",
      "backbone.blocks.29.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.29.layernorm2.beta (1310720,)\n",
      "backbone.blocks.29.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.projection.bias (1310720,)\n",
      "backbone.blocks.29.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.dense1.bias (2560,)\n",
      "backbone.blocks.29.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.dense2.bias (2560,)\n",
      "backbone.blocks.29.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.29.attention.dense3.bias (2560,)\n",
      "backbone.blocks.29.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.29.output.mapping.bias (10240,)\n",
      "backbone.blocks.29.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.29.output.projection.bias (1310720,)\n",
      "backbone.blocks.30.layernorm1.gamma (1310720,)\n",
      "backbone.blocks.30.layernorm1.beta (1310720,)\n",
      "backbone.blocks.30.layernorm2.gamma (1310720,)\n",
      "backbone.blocks.30.layernorm2.beta (1310720,)\n",
      "backbone.blocks.30.attention.projection.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.projection.bias (1310720,)\n",
      "backbone.blocks.30.attention.dense1.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.dense1.bias (2560,)\n",
      "backbone.blocks.30.attention.dense2.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.dense2.bias (2560,)\n",
      "backbone.blocks.30.attention.dense3.weight (2560, 2560)\n",
      "backbone.blocks.30.attention.dense3.bias (2560,)\n",
      "backbone.blocks.30.output.mapping.weight (20480, 1280)\n",
      "backbone.blocks.30.output.mapping.bias (10240,)\n",
      "backbone.blocks.30.output.projection.weight (10240, 2560)\n",
      "backbone.blocks.30.output.projection.bias (1310720,)\n",
      "backbone.layernorm.gamma (1310720,)\n",
      "backbone.layernorm.beta (1310720,)\n",
      "backbone.top_query_layer.layernorm1.gamma (1310720,)\n",
      "backbone.top_query_layer.layernorm1.beta (1310720,)\n",
      "backbone.top_query_layer.layernorm2.gamma (1310720,)\n",
      "backbone.top_query_layer.layernorm2.beta (1310720,)\n",
      "backbone.top_query_layer.attention.projection.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.projection.bias (1310720,)\n",
      "backbone.top_query_layer.attention.dense1.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.dense1.bias (2560,)\n",
      "backbone.top_query_layer.attention.dense2.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.dense2.bias (2560,)\n",
      "backbone.top_query_layer.attention.dense3.weight (2560, 2560)\n",
      "backbone.top_query_layer.attention.dense3.bias (2560,)\n",
      "backbone.top_query_layer.output.mapping.weight (20480, 1280)\n",
      "backbone.top_query_layer.output.mapping.bias (10240,)\n",
      "backbone.top_query_layer.output.projection.weight (10240, 2560)\n",
      "backbone.top_query_layer.output.projection.bias (1310720,)\n",
      "global_step (512,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in weights.items():\n",
    "    if hasattr(v, 'shape'):\n",
    "        print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2, 40000)\n"
     ]
    }
   ],
   "source": [
    "from models import TFPanGuAlphaLMHeadModel\n",
    "from transformers import GPT2Config\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=40000,\n",
    "    n_positions=1024,\n",
    "    n_ctx=1024,\n",
    "    n_embd=2560,\n",
    "    n_layer=31,\n",
    "    n_head=32\n",
    ")\n",
    "model = TFPanGuAlphaLMHeadModel(config)\n",
    "input = tf.constant([[1, 2]])\n",
    "out = model(input)[0]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "setting transformer/wpe/embeddings\n",
      "setting transformer/wte/weight\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._0/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._1/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._2/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._3/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._4/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._5/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._6/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._7/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._8/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._9/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._10/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._11/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._12/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._13/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._14/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._15/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._16/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._17/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._18/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._19/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._20/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._21/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._22/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._23/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._24/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._25/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._26/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._27/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._28/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._29/mlp/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/attn/c_proj/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/h_._30/mlp/c_proj/bias:0\n",
      "setting transformer/ln_f/gamma\n",
      "setting transformer/ln_f/beta\n",
      "setting transformer/top_query_embedding\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_1/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_1/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_proj/bias:0\n",
      "(2560, 5120) (2560, 5120)\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn_query/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/attn/c_attn_query/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_2/gamma:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/ln_2/beta:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_fc/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_fc/bias:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_proj/weight:0\n",
      "setting layer tf_pan_gu_alpha_lm_head_model/transformer/top_query_layer/mlp/c_proj/bias:0\n",
      "[]\n",
      "391 391\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "new_weights = []\n",
    "\n",
    "download_path = '/home/mymusise/Downloads/pangu_model/'\n",
    "not_set = []\n",
    "for weight in model.weights:\n",
    "    num_layer = 0\n",
    "    if 'h_._' in weight.name:\n",
    "        num_layer = re.findall(r'transformer/h_._(\\d+)', weight.name)[0]\n",
    "        block_name = f\"backbone.blocks.{num_layer}\"\n",
    "    if 'top_query_layer' in weight.name:\n",
    "        block_name = 'backbone.top_query_layer'\n",
    "    \n",
    "    if 'transformer/wte/weight:0' in weight.name:\n",
    "        w = np.load(f\"{download_path}/word_embedding.npy\")\n",
    "        assert w.shape == (40000, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/wte/weight')\n",
    "    elif 'transformer/wpe/embeddings:0' in weight.name:\n",
    "        w = np.load(f\"{download_path}/position_embedding.npy\")\n",
    "        assert w.shape == (1024, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/wpe/embeddings')\n",
    "    elif 'top_query_embedding' in weight.name:\n",
    "        w = np.load(f\"{download_path}/top_query_embedding.npy\")\n",
    "        assert w.shape == (1024, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/top_query_embedding')\n",
    "    elif f'/ln_1/gamma:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm1.gamma')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif f'/ln_1/beta:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm1.beta')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "\n",
    "\n",
    "    ### normal transformer  ###\n",
    "    elif 'attn/c_attn/weight:0' in weight.name and 'top_query' not in weight.name:\n",
    "        query = get_weight(f'{block_name}.attention.dense1.weight')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.weight')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.weight')\n",
    "        w = np.concatenate([query, key, value], axis=1)\n",
    "        assert w.shape == (2560, 7680)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn/bias:0' in weight.name and 'top_query' not in weight.name:\n",
    "        query = get_weight(f'{block_name}.attention.dense1.bias')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.bias')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.bias')\n",
    "        w = np.concatenate([query, key, value], axis=0)\n",
    "        w = w.reshape(1,7680) # ???\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/weight:0' in weight.name and 'top_query' not in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.weight')\n",
    "        assert w.shape == (2560, 2560)\n",
    "        # w = np.transpose(w)  # ???\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/bias:0' in weight.name and 'top_query' not in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.bias')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        w = w.reshape(1, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "\n",
    "\n",
    "    ###  top_quert ###\n",
    "    elif 'attn/c_attn/weight:0' in weight.name and 'top_query' in weight.name:\n",
    "        # query = get_weight(f'{block_name}.attention.dense1.weight')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.weight')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.weight')\n",
    "        w = np.concatenate([key, value], axis=1)\n",
    "        assert w.shape == (2560, 2560 * 2)\n",
    "        print(w.shape, weight.shape)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn/bias:0' in weight.name and 'top_query' in weight.name:\n",
    "        # query = get_weight(f'{block_name}.attention.dense1.bias')\n",
    "        key = get_weight(f'{block_name}.attention.dense2.bias')\n",
    "        value = get_weight(f'{block_name}.attention.dense3.bias')\n",
    "        w = np.concatenate([key, value], axis=0)\n",
    "        w = w.reshape(1,2560 * 2)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn_query/weight:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.dense1.weight')\n",
    "        assert w.shape == (2560, 2560)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_attn_query/bias:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.dense1.bias')\n",
    "        w = w.reshape(1,2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/weight:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.weight')\n",
    "        assert w.shape == (2560, 2560)\n",
    "        # w = np.transpose(w)  # ???\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'attn/c_proj/bias:0' in weight.name and 'top_query' in weight.name:\n",
    "        w = get_weight(f'{block_name}.attention.projection.bias')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        w = w.reshape(1, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    ### top query ###\n",
    "\n",
    "\n",
    "    elif f'/ln_2/gamma:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm2.gamma')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif f'/ln_2/beta:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.layernorm2.beta')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == (2560, )\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_fc/weight:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.mapping.weight')\n",
    "        assert w.shape == (10240 * 2, 2560 /2)  # TODO: \n",
    "        w = np.reshape(w, (2560, 10240))\n",
    "        # assert w.shape == (10240, 2560)\n",
    "        # w = np.transpose(w)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_fc/bias:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.mapping.bias')\n",
    "        assert w.shape == (10240, )\n",
    "        w = w.reshape(1, 10240)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_proj/weight:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.projection.weight')\n",
    "        assert w.shape == (10240, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'mlp/c_proj/bias:0' in weight.name:\n",
    "        w = get_weight(f'{block_name}.output.projection.bias')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        w = w.reshape(1, 2560)\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {weight.name}')\n",
    "    elif 'transformer/ln_f/gamma:0' in weight.name:\n",
    "        w = get_weight(f'backbone.layernorm.gamma')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/ln_f/gamma')\n",
    "    elif 'transformer/ln_f/beta:0' in weight.name:\n",
    "        w = get_weight(f'backbone.layernorm.beta')\n",
    "        assert w.shape == (2560 * 512, )\n",
    "        w = w[:2560,]\n",
    "        assert w.shape == weight.shape\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/ln_f/beta')\n",
    "    else:\n",
    "        not_set.append(weight.name)\n",
    "\n",
    "print(not_set)\n",
    "print(len(model.weights), len(new_weights))\n",
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      ",,<eot>2,\n",
      ",,,,,,\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, TFGPT2LMHeadModel\n",
    "# add spicel process \n",
    "class XLNetTokenizer(XLNetTokenizer):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "\n",
    "    def _tokenize(self, text, *args, **kwargs):\n",
    "        text = [x.translate(self.translator) for x in jieba.cut(text, cut_all=False)]\n",
    "        text = \" \".join(text)\n",
    "        return super()._tokenize(text, *args, **kwargs)\n",
    "\n",
    "    def _decode(self, *args, **kwargs):\n",
    "        text = super()._decode(*args, **kwargs)\n",
    "        text = text.replace(' ', '').replace('\\u2582', ' ').replace('\\u2583', '\\n')\n",
    "        return text\n",
    "\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('/data2/PanGu-Alpha')\n",
    "\n",
    "\n",
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "\n",
    "\n",
    "# class TextGenerationPipeline(TextGenerationPipeline):\n",
    "\n",
    "TextGenerationPipeline.ALLOWED_MODELS.append(\"TFPanGuAlphaLMHeadModel\")\n",
    "\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "texts = [\n",
    "    '',\n",
    "    # ', ',\n",
    "    # ',',\n",
    "    # '',\n",
    "    # \"\"\"\n",
    "    # 5436358\n",
    "\n",
    "    # \n",
    "    # ||||\n",
    "    # |||2|\n",
    "    # |||5|\n",
    "    # |||4|\n",
    "    # |||36|\n",
    "    # \"\"\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    token_len = len(tokenizer._tokenize(text))\n",
    "    # print(text_generater(text, max_length=token_len + 200, top_k=1, use_cache=True, prefix='')[0]['generated_text'])\n",
    "    print(text_generater(text, max_length=token_len + 16, do_sample=True, repetition_penalty=1.3)[0]['generated_text'])\n",
    "    print(text_generater(text, max_length=token_len + 16, do_sample=True, top_k=3)[0]['generated_text'])"
   ]
  }
 ]
}